{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-LOC',\n",
       "  'score': 0.55669767,\n",
       "  'index': 10,\n",
       "  'word': '▁d',\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.95578015,\n",
       "  'index': 12,\n",
       "  'word': 'Italie',\n",
       "  'start': 39,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9981791,\n",
       "  'index': 16,\n",
       "  'word': '▁V',\n",
       "  'start': 55,\n",
       "  'end': 57},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9979278,\n",
       "  'index': 17,\n",
       "  'word': 'errière',\n",
       "  'start': 57,\n",
       "  'end': 64},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99829894,\n",
       "  'index': 18,\n",
       "  'word': 's',\n",
       "  'start': 64,\n",
       "  'end': 65},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9855219,\n",
       "  'index': 31,\n",
       "  'word': '▁M',\n",
       "  'start': 112,\n",
       "  'end': 114},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9845025,\n",
       "  'index': 32,\n",
       "  'word': '.',\n",
       "  'start': 114,\n",
       "  'end': 115},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.8523049,\n",
       "  'index': 33,\n",
       "  'word': '▁le',\n",
       "  'start': 115,\n",
       "  'end': 118},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.87298524,\n",
       "  'index': 34,\n",
       "  'word': '▁maire',\n",
       "  'start': 118,\n",
       "  'end': 124},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.92345726,\n",
       "  'index': 74,\n",
       "  'word': '▁M',\n",
       "  'start': 261,\n",
       "  'end': 263},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.91418386,\n",
       "  'index': 75,\n",
       "  'word': '.',\n",
       "  'start': 263,\n",
       "  'end': 264},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9488357,\n",
       "  'index': 76,\n",
       "  'word': '▁de',\n",
       "  'start': 264,\n",
       "  'end': 267},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99203897,\n",
       "  'index': 77,\n",
       "  'word': '▁R',\n",
       "  'start': 267,\n",
       "  'end': 269},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99149936,\n",
       "  'index': 78,\n",
       "  'word': 'ê',\n",
       "  'start': 269,\n",
       "  'end': 270},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9911446,\n",
       "  'index': 79,\n",
       "  'word': 'nal',\n",
       "  'start': 270,\n",
       "  'end': 273},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9943797,\n",
       "  'index': 96,\n",
       "  'word': '▁Légion',\n",
       "  'start': 355,\n",
       "  'end': 362},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9943036,\n",
       "  'index': 97,\n",
       "  'word': '▁d',\n",
       "  'start': 362,\n",
       "  'end': 364},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9942684,\n",
       "  'index': 99,\n",
       "  'word': 'honneur',\n",
       "  'start': 365,\n",
       "  'end': 372}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/54/81b1c3c574a1ffde54b0c82ed2a37d81395709cdd5f50e59970aeed5d95e/torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 881.9MB 1.8kB/s eta 0:00:01  3% |█▏                              | 31.2MB 77.8MB/s eta 0:00:11    16% |█████▍                          | 147.3MB 80.5MB/s eta 0:00:10    19% |██████▏                         | 170.9MB 72.3MB/s eta 0:00:10    28% |█████████                       | 248.8MB 78.0MB/s eta 0:00:09    40% |█████████████                   | 355.3MB 74.2MB/s eta 0:00:08    44% |██████████████▏                 | 391.2MB 75.7MB/s eta 0:00:070.5MB 75.2MB/s eta 0:00:06��████████████████▎             | 504.5MB 74.1MB/s eta 0:00:06�██▌             | 508.5MB 80.4MB/s eta 0:00:057MB 74.1MB/s eta 0:00:05�███████████▉             | 518.4MB 70.3MB/s eta 0:00:06█             | 522.7MB 81.3MB/s eta 0:00:05█████████████             | 526.5MB 79.8MB/s eta 0:00:05��███████████▎            | 531.0MB 68.1MB/s eta 0:00:06�███▍            | 534.8MB 73.5MB/s eta 0:00:05██████████▌            | 538.3MB 76.1MB/s eta 0:00:05��█▊            | 543.5MB 71.7MB/s eta 0:00:05�████████▉            | 547.1MB 76.8MB/s eta 0:00:05█            | 550.8MB 72.8MB/s eta 0:00:05 |████████████████████▎           | 557.9MB 73.3MB/s eta 0:00:05�███████████████████▍           | 562.0MB 77.2MB/s eta 0:00:05ta 0:00:05█████████████████▋           | 568.4MB 78.3MB/s eta 0:00:05:04 |████████████████████▉           | 575.3MB 70.9MB/s eta 0:00:05/s eta 0:00:04��█████████████▎          | 585.1MB 82.2MB/s eta 0:00:04.2MB/s eta 0:00:04��██████████▌          | 592.2MB 76.2MB/s eta 0:00:04|█████████████████████▋          | 595.4MB 79.7MB/s eta 0:00:04��████▉          | 601.8MB 78.4MB/s eta 0:00:04�████████          | 607.5MB 68.1MB/s eta 0:00:05�█████████████████████▏         | 611.3MB 74.5MB/s eta 0:00:04�▎         | 614.3MB 72.7MB/s eta 0:00:04 0:00:044�███████████████▊         | 627.3MB 80.5MB/s eta 0:00:04�███████         | 631.5MB 72.3MB/s eta 0:00:0436.1MB 75.0MB/s eta 0:00:04% |███████████████████████▏        | 640.0MB 70.5MB/s eta 0:00:04��██████▎        | 642.8MB 72.1MB/s eta 0:00:04��████████████████▌        | 646.3MB 75.1MB/s eta 0:00:04�        | 649.1MB 75.2MB/s eta 0:00:04�████▋        | 651.9MB 71.8MB/s eta 0:00:04030359.9MB 58.6MB/s eta 0:00:040:00:03��███▏       | 665.3MB 71.6MB/s eta 0:00:04 75% |████████████████████████▎       | 668.4MB 53.6MB/s eta 0:00:04 76% |████████████████████████▍       | 671.0MB 72.6MB/s eta 0:00:03    76% |████████████████████████▍       | 673.6MB 74.3MB/s eta 0:00:037% |████████████████████████▊       | 680.5MB 66.1MB/s eta 0:00:047% |████████████████████████▉       | 682.9MB 69.0MB/s eta 0:00:03��████████▏      | 693.1MB 72.0MB/s eta 0:00:03�      | 695.5MB 79.1MB/s eta 0:00:03MB 52.3MB/s eta 0:00:04 701.5MB 69.0MB/s eta 0:00:033██████▋      | 706.4MB 75.3MB/s eta 0:00:03 | 710.2MB 80.1MB/s eta 0:00:03�█████████████████████      | 715.4MB 76.7MB/s eta 0:00:03�███████████████████████      | 719.3MB 70.9MB/s eta 0:00:03████▏     | 721.7MB 53.8MB/s eta 0:00:03███████████████████████▎     | 724.1MB 78.2MB/s eta 0:00:03��███████████████████████▍     | 726.6MB 76.4MB/s eta 0:00:03��██████▌     | 729.4MB 71.1MB/s eta 0:00:03███▋     | 732.2MB 74.6MB/s eta 0:00:03�     | 735.7MB 79.0MB/s eta 0:00:02�████████▉     | 738.6MB 71.5MB/s eta 0:00:03██████████████████████████     | 744.9MB 76.7MB/s eta 0:00:02MB 77.7MB/s eta 0:00:02   85% |███████████████████████████▎    | 751.9MB 81.7MB/s eta 0:00:02ta 0:00:03███████████▌    | 757.4MB 74.6MB/s eta 0:00:02█████▋    | 759.6MB 73.9MB/s eta 0:00:028MB 72.8MB/s eta 0:00:02�███████████████████    | 770.5MB 74.1MB/s eta 0:00:02██████████    | 774.7MB 82.1MB/s eta 0:00:02██████████████▎   | 778.3MB 75.0MB/s eta 0:00:02% |████████████████████████████▍   | 781.0MB 74.4MB/s eta 0:00:02   88% |████████████████████████████▍   | 783.5MB 57.8MB/s eta 0:00:02�██▌   | 786.1MB 71.4MB/s eta 0:00:02�███████████████████▋   | 787.8MB 72.7MB/s eta 0:00:02   89% |████████████████████████████▊   | 790.4MB 57.2MB/s eta 0:00:02�██▊   | 793.0MB 74.6MB/s eta 0:00:02 0:00:02███████████████▏  | 803.9MB 69.4MB/s eta 0:00:02��███▎  | 806.5MB 78.3MB/s eta 0:00:01.9MB 56.6MB/s eta 0:00:02�███▍  | 811.4MB 71.8MB/s eta 0:00:01▌  | 814.4MB 78.8MB/s eta 0:00:01 78.3MB/s eta 0:00:01��████████████████▉  | 822.6MB 75.9MB/s eta 0:00:01��██████████████████████  | 825.1MB 79.4MB/s eta 0:00:01██████  | 828.9MB 70.9MB/s eta 0:00:01███████▏ | 831.5MB 72.3MB/s eta 0:00:01��██████████████████████████▎ | 834.6MB 81.2MB/s eta 0:00:01████████▌ | 840.6MB 81.1MB/s eta 0:00:01 | 843.9MB 78.7MB/s eta 0:00:01████████████████████████████▊ | 847.5MB 73.3MB/s eta 0:00:0116% |███████████████████████████████ | 852.4MB 61.0MB/s eta 0:00:01�| 858.2MB 80.1MB/s eta 0:00:01�████████████████████████▏| 860.3MB 58.0MB/s eta 0:00:017% |███████████████████████████████▎| 862.5MB 78.6MB/s eta 0:00:01��███████████▍| 864.7MB 80.4MB/s eta 0:00:01��███████████▌| 867.4MB 77.6MB/s eta 0:00:01�███████████████▋| 870.3MB 55.2MB/s eta 0:00:01�██████████████████▊| 873.7MB 77.0MB/s eta 0:00:01��████▉| 876.9MB 70.4MB/s eta 0:00:01�██████████████████| 879.3MB 57.0MB/s eta 0:00:01�██████████████████████████| 881.5MB 77.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses; python_version < \"3.7\" (from torch)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting typing-extensions (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/6b/44f7f8f1e110027cf88956b59f2fad776cca7e1704396d043f89effd3a0e/typing_extensions-4.1.1-py3-none-any.whl\n",
      "Installing collected packages: dataclasses, typing-extensions, torch\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 345, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 323, in clobber\n",
      "    shutil.copyfile(srcfile, destfile)\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 121, in copyfile\n",
      "    with open(dst, 'wb') as fdst:\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/anaconda3/lib/python3.6/site-packages/dataclasses.py'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading https://files.pythonhosted.org/packages/38/03/c963ecdf98fae15286437ae533750e2c39e988b7d8c86fad4dbc73a3a146/torchvision-0.11.2-cp36-cp36m-manylinux1_x86_64.whl (23.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 23.3MB 69kB/s  eta 0:00:01   17% |█████▌                          | 4.0MB 58.9MB/s eta 0:00:01    44% |██████████████▍                 | 10.4MB 61.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.6/site-packages (from torchvision)\n",
      "Collecting pillow!=8.3.0,>=5.3.0 (from torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/2a/2fc11b54e2742db06297f7fa7f420a0e3069fdcf0e4b57dfec33f0b08622/Pillow-8.4.0.tar.gz (49.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 49.4MB 28kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.10.1 (from torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/f5/b76d021f06e50f770d3f6c1a1b50b62a69e587b1f0db7248269c4be21206/torch-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (881.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 881.9MB 1.8kB/s eta 0:00:01    13% |████▎                           | 116.9MB 71.4MB/s eta 0:00:11    25% |████████                        | 222.5MB 75.4MB/s eta 0:00:09    29% |█████████▎                      | 257.2MB 74.5MB/s eta 0:00:09    30% |██████████                      | 272.6MB 72.6MB/s eta 0:00:09    41% |█████████████▍                  | 368.2MB 77.1MB/s eta 0:00:07    61% |███████████████████▊            | 544.7MB 71.5MB/s eta 0:00:05    64% |████████████████████▊           | 570.7MB 76.9MB/s eta 0:00:05    68% |██████████████████████          | 606.1MB 76.1MB/s eta 0:00:04    74% |███████████████████████▊        | 654.0MB 73.3MB/s eta 0:00:04    76% |████████████████████████▋       | 677.8MB 72.7MB/s eta 0:00:03    79% |█████████████████████████▎      | 697.8MB 75.1MB/s eta 0:00:03    85% |███████████████████████████▍    | 753.6MB 75.4MB/s eta 0:00:02    88% |████████████████████████████▏   | 777.2MB 76.3MB/s eta 0:00:02    89% |████████████████████████████▉   | 793.2MB 72.1MB/s eta 0:00:02   93% |█████████████████████████████▉  | 823.3MB 71.0MB/s eta 0:00:01█████████████████████  | 825.6MB 73.4MB/s eta 0:00:01█████████████▏ | 831.1MB 74.6MB/s eta 0:00:0101�█████████████▎ | 835.7MB 68.2MB/s eta 0:00:01B 72.6MB/s eta 0:00:01��███████▌ | 839.8MB 73.1MB/s eta 0:00:01��█████████████████████████▋ | 842.4MB 70.8MB/s eta 0:00:01�████████▋ | 844.5MB 72.5MB/s eta 0:00:01��████████████████▊ | 846.6MB 69.1MB/s eta 0:00:01�█████████████▉ | 848.9MB 69.2MB/s eta 0:00:01B 67.3MB/s eta 0:00:0101████████ | 855.5MB 66.1MB/s eta 0:00:01��███████████▏| 859.5MB 68.2MB/s eta 0:00:01 97% |███████████████████████████████▎| 862.5MB 67.0MB/s eta 0:00:01�██████████████▌| 868.0MB 72.1MB/s eta 0:00:01/s eta 0:00:01███████████████▉| 878.4MB 71.5MB/s eta 0:00:01�██████████████████| 880.2MB 44.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses; python_version < \"3.7\" (from torch==1.10.1->torchvision)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting typing-extensions (from torch==1.10.1->torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/6b/44f7f8f1e110027cf88956b59f2fad776cca7e1704396d043f89effd3a0e/typing_extensions-4.1.1-py3-none-any.whl\n",
      "Building wheels for collected packages: pillow\n",
      "\u001b[33m  Building wheel for pillow failed: [Errno 28] No space left on device: '/home/doyard/.cache/pip/wheels'\u001b[0m\n",
      "Failed to build pillow\n",
      "Installing collected packages: pillow, dataclasses, typing-extensions, torch, torchvision\n",
      "  Found existing installation: Pillow 4.2.1\n",
      "    Uninstalling Pillow-4.2.1:\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 544, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/opt/anaconda3/lib/python3.6/site-packages/PIL' -> '/scratch/students/doyard/sentiment-evolution-in-characters-network/scripts/pip-hkedrkr0-uninstall/opt/anaconda3/lib/python3.6/site-packages/PIL'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py\", line 778, in install\n",
      "    requirement.uninstall(auto_confirm=True)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 754, in uninstall\n",
      "    paths_to_remove.remove(auto_confirm)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_uninstall.py\", line 115, in remove\n",
      "    renames(path, new_path)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/utils/__init__.py\", line 267, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 556, in move\n",
      "    rmtree(src)\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 480, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 438, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 436, in _rmtree_safe_fd\n",
      "    os.unlink(name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'SgiImagePlugin.py'\u001b[0m\n",
      "Collecting torchgeometry\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/d6/3f6820c0589bc3876080c59b58a3bad11af746a7b46f364b1cde7972bd72/torchgeometry-0.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.0.0 (from torchgeometry)\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/54/81b1c3c574a1ffde54b0c82ed2a37d81395709cdd5f50e59970aeed5d95e/torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 881.9MB 1.8kB/s eta 0:00:01 0% |▎                               | 8.5MB 68.2MB/s eta 0:00:13    9% |███                             | 85.2MB 67.2MB/s eta 0:00:12    15% |█████                           | 139.7MB 68.5MB/s eta 0:00:11    21% |███████                         | 190.7MB 68.8MB/s eta 0:00:11    52% |█████████████████               | 465.8MB 75.2MB/s eta 0:00:06    61% |███████████████████▊            | 543.2MB 73.8MB/s eta 0:00:05    78% |█████████████████████████▎      | 696.3MB 72.1MB/s eta 0:00:03    85% |███████████████████████████▍    | 755.4MB 73.8MB/s eta 0:00:02    88% |████████████████████████████▎   | 779.1MB 73.6MB/s eta 0:00:02    92% |█████████████████████████████▊  | 818.3MB 72.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses; python_version < \"3.7\" (from torch>=1.0.0->torchgeometry)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting typing-extensions (from torch>=1.0.0->torchgeometry)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/6b/44f7f8f1e110027cf88956b59f2fad776cca7e1704396d043f89effd3a0e/typing_extensions-4.1.1-py3-none-any.whl\n",
      "Installing collected packages: dataclasses, typing-extensions, torch, torchgeometry\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 345, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/opt/anaconda3/lib/python3.6/site-packages/pip/wheel.py\", line 323, in clobber\n",
      "    shutil.copyfile(srcfile, destfile)\n",
      "  File \"/opt/anaconda3/lib/python3.6/shutil.py\", line 121, in copyfile\n",
      "    with open(dst, 'wb') as fdst:\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/anaconda3/lib/python3.6/site-packages/dataclasses.py'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...........\n",
      "Solving package specifications: .\n",
      "\n",
      "Package plan for installation in environment /opt/anaconda3:\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    _libgcc_mutex:          0.1-main             \n",
      "    conda-package-handling: 1.7.3-py36h27cfd23_1 \n",
      "    tqdm:                   4.63.0-pyhd3eb1b0_0  \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    conda:                  4.3.30-py36h5d9f9f4_0 --> 4.10.3-py36h06a4308_0\n",
      "    conda-env:              2.6.0-h36134e3_1      --> 2.6.0-1              \n",
      "    libgcc-ng:              7.2.0-h7cc24e2_2      --> 9.1.0-hdf63c60_0     \n",
      "    pycosat:                0.6.2-py36h1a0ea17_1  --> 0.6.3-py36h27cfd23_0 \n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install torchgeometry\n",
    "!conda install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_text =  get_book_text('798-8')\n",
    "ner_model = 'mrm8488/mobilebert-finetuned-ner'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ner_model)\n",
    "model = AutoModelForTokenClassification.from_pretrained(ner_model)\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "sentence_level_book = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', book_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new entity tokens\n",
      "[{'entity': 'I-PER', 'score': 0.9980604, 'index': 42, 'word': 'm', 'start': 113, 'end': 114}, {'entity': 'I-PER', 'score': 0.9974752, 'index': 44, 'word': 'le', 'start': 116, 'end': 118}, {'entity': 'I-PER', 'score': 0.93767214, 'index': 45, 'word': 'mai', 'start': 119, 'end': 122}, {'entity': 'I-PER', 'score': 0.906227, 'index': 46, 'word': '##re', 'start': 122, 'end': 124}, {'entity': 'I-PER', 'score': 0.9871251, 'index': 48, 'word': 'jacob', 'start': 126, 'end': 131}, {'entity': 'I-PER', 'score': 0.990449, 'index': 49, 'word': '##in', 'start': 131, 'end': 133}, {'entity': 'I-PER', 'score': 0.955765, 'index': 51, 'word': 'bon', 'start': 137, 'end': 140}, {'entity': 'I-PER', 'score': 0.8932861, 'index': 54, 'word': '##ste', 'start': 146, 'end': 149}, {'entity': 'I-PER', 'score': 0.9953166, 'index': 97, 'word': 'm', 'start': 262, 'end': 263}, {'entity': 'I-PER', 'score': 0.9966055, 'index': 99, 'word': 'de', 'start': 265, 'end': 267}, {'entity': 'I-PER', 'score': 0.9961195, 'index': 100, 'word': 'renal', 'start': 268, 'end': 273}]\n",
      "line words\n",
      "['Un', 'vieux', 'chirurgien', '-', 'major', 'de', 'l', \"'\", 'armée', 'd', \"'\", 'Italie', ',', 'retiré', 'à', 'Verrières', ',', 'et', 'qui', 'de', 'son', 'vivant', 'était', 'à', 'la', 'fois', ',', 'suivant', 'M', '.', 'le', 'maire', ',', 'jacobin', 'et', 'bonapartiste', ',', 'osa', 'bien', 'un', 'jour', 'se', 'plaindre', 'à', 'lui', 'de', 'la', 'mutilation', 'périodique', 'de', 'ces', 'beaux', 'arbres', '.', '-', '-', 'J', \"'\", 'aime', 'l', \"'\", 'ombre', ',', 'répondit', 'M', '.', 'de', 'Rênal', 'avec', 'la', 'nuance', 'de', 'hauteur', 'convenable', 'quand', 'on', 'parle', 'à', 'un', 'chirurgien', ',', 'membre', 'de', 'la', 'Légion', 'd', \"'\", 'honneur', ',', 'j', \"'\", 'aime', 'l', \"'\", 'ombre', ',', 'je', 'fais', 'tailler', 'mes', 'arbres', 'pour', 'donner', 'de', 'l', \"'\", 'ombre', ',', 'et', 'je', 'ne', 'conçois', 'pas', 'qu', \"'\", 'un', 'arbre', 'soit', 'fait', 'pour', 'autre', 'chose', ',', 'quand', 'toutefois', ',', 'comme', 'l', \"'\", 'utile', 'noyer', ',', 'il', '_', 'ne', 'rapporte', 'pas', 'de', 'revenu', '_', '.']\n"
     ]
    }
   ],
   "source": [
    "l=sentence_level_book[65]\n",
    "a,b,c = get_line_entities(l, [], [], 0, tokenizer, nlp,\n",
    "                     False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '▁d',\n",
       "  'score': 0.5566989183425903,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 10,\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'word': 'Italie',\n",
       "  'score': 0.9557802677154541,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 12,\n",
       "  'start': 39,\n",
       "  'end': 45},\n",
       " {'word': '▁V',\n",
       "  'score': 0.998179018497467,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 16,\n",
       "  'start': 55,\n",
       "  'end': 57},\n",
       " {'word': 'errière',\n",
       "  'score': 0.9979278445243835,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 17,\n",
       "  'start': 57,\n",
       "  'end': 64},\n",
       " {'word': 's',\n",
       "  'score': 0.9982990026473999,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 18,\n",
       "  'start': 64,\n",
       "  'end': 65},\n",
       " {'word': '▁M',\n",
       "  'score': 0.9855217337608337,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 31,\n",
       "  'start': 112,\n",
       "  'end': 114},\n",
       " {'word': '.',\n",
       "  'score': 0.9845024347305298,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 32,\n",
       "  'start': 114,\n",
       "  'end': 115},\n",
       " {'word': '▁le',\n",
       "  'score': 0.8523029685020447,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 33,\n",
       "  'start': 115,\n",
       "  'end': 118},\n",
       " {'word': '▁maire',\n",
       "  'score': 0.8729842901229858,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 34,\n",
       "  'start': 118,\n",
       "  'end': 124},\n",
       " {'word': '▁M',\n",
       "  'score': 0.9234569668769836,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 74,\n",
       "  'start': 261,\n",
       "  'end': 263},\n",
       " {'word': '.',\n",
       "  'score': 0.9141836166381836,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 75,\n",
       "  'start': 263,\n",
       "  'end': 264},\n",
       " {'word': '▁de',\n",
       "  'score': 0.9488356113433838,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 76,\n",
       "  'start': 264,\n",
       "  'end': 267},\n",
       " {'word': '▁R',\n",
       "  'score': 0.992038905620575,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 77,\n",
       "  'start': 267,\n",
       "  'end': 269},\n",
       " {'word': 'ê',\n",
       "  'score': 0.9914994239807129,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 78,\n",
       "  'start': 269,\n",
       "  'end': 270},\n",
       " {'word': 'nal',\n",
       "  'score': 0.991144597530365,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 79,\n",
       "  'start': 270,\n",
       "  'end': 273},\n",
       " {'word': '▁Légion',\n",
       "  'score': 0.9943797588348389,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 96,\n",
       "  'start': 355,\n",
       "  'end': 362},\n",
       " {'word': '▁d',\n",
       "  'score': 0.9943034648895264,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 97,\n",
       "  'start': 362,\n",
       "  'end': 364},\n",
       " {'word': 'honneur',\n",
       "  'score': 0.9942684173583984,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 99,\n",
       "  'start': 365,\n",
       "  'end': 372}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7929/7929 [09:56<00:00, 13.28it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_noir_id = '798-8'\n",
    "(rouge_noir_text, \n",
    " rouge_noir_ent_tokens, \n",
    " rouge_noir_ent_words) = get_person_entities(rouge_noir_id, grouped_entities=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_word\n",
       "julien        1166\n",
       "rênal          595\n",
       "mathilde       340\n",
       "mole           170\n",
       "pirard         106\n",
       "abbé            81\n",
       "croisenois      53\n",
       "sorel           53\n",
       "derville        50\n",
       "norbert         49\n",
       "fervaques       38\n",
       "élisa           29\n",
       "valenod         28\n",
       "napoléon        27\n",
       "altamira        27\n",
       "caylus          27\n",
       "louis           24\n",
       "trouva          23\n",
       "chélan          21\n",
       "amanda          19\n",
       "geronimo        17\n",
       "frilair         16\n",
       "stanislas       16\n",
       "maslon          14\n",
       "don             14\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save entities into a dataframe, and to the disk\n",
    "rouge_noir_df = pd.DataFrame(rouge_noir_ent_words)\n",
    "# view top 25 entities\n",
    "(rouge_noir_df\n",
    " .drop_duplicates('total_word_index')\n",
    " .groupby('full_word')\n",
    " .count()\n",
    " .sort_values(by='score', ascending=False)\n",
    ")['score'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save entities into a dataframe, and to the disk\n",
    "rouge_noir_df = pd.DataFrame(rouge_noir_ent_words)\n",
    "# rouge_noir_df['full_word'] =  rouge_noir_df['full_word'].apply(lambda s: s.lower())\n",
    "rouge_noir_df.to_csv('../data/book_dfs/rouge_noir_df.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_word\n",
       "julien        450\n",
       "é             369\n",
       "mme           208\n",
       "mathilde       98\n",
       "è              75\n",
       "valenod        70\n",
       "mlle           63\n",
       "mole           54\n",
       "ê              48\n",
       "marquis        43\n",
       "ch             32\n",
       "tait           31\n",
       "sorel          29\n",
       "re             24\n",
       "fouqu          24\n",
       "disait         21\n",
       "tre            19\n",
       "comte          19\n",
       "pr             18\n",
       "ç              17\n",
       "grand          16\n",
       "norbert        16\n",
       "derville       15\n",
       "û              14\n",
       "croisenois     14\n",
       "pensa          14\n",
       "pirard         14\n",
       "res            13\n",
       "chevalier      11\n",
       "nal            11\n",
       "homme          11\n",
       "monsieur       11\n",
       "jour           10\n",
       "mar            10\n",
       "chambre        10\n",
       "napol           9\n",
       "saint           9\n",
       "abb             9\n",
       "tanbeau         8\n",
       "dieu            8\n",
       "esprit          8\n",
       "appert          8\n",
       "maire           7\n",
       "ami             7\n",
       "marquise        7\n",
       "duc             7\n",
       "amour           7\n",
       "caract          7\n",
       "altamira        7\n",
       "voir            7\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view top 25 entities\n",
    "(rouge_noir_df\n",
    " .drop_duplicates('total_word_index')\n",
    " .groupby('full_word')\n",
    " .count()\n",
    " .sort_values(by='score', ascending=False)\n",
    ")['score'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_word\n",
       "julien        1166\n",
       "rênal          595\n",
       "mathilde       340\n",
       "mole           170\n",
       "pirard         106\n",
       "abbé            81\n",
       "croisenois      53\n",
       "sorel           53\n",
       "derville        50\n",
       "norbert         49\n",
       "fervaques       38\n",
       "élisa           29\n",
       "valenod         28\n",
       "napoléon        27\n",
       "altamira        27\n",
       "caylus          27\n",
       "louis           24\n",
       "trouva          23\n",
       "chélan          21\n",
       "amanda          19\n",
       "geronimo        17\n",
       "frilair         16\n",
       "stanislas       16\n",
       "maslon          14\n",
       "don             14\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save entities into a dataframe, and to the disk\n",
    "rouge_noir_df = pd.DataFrame(rouge_noir_ent_words)\n",
    "# rouge_noir_df['full_word'] =  rouge_noir_df['full_word'].apply(lambda s: s.lower())\n",
    "rouge_noir_df.to_csv('../data/book_dfs/798-8.csv', index=False) \n",
    "\n",
    "# view top 25 entities\n",
    "(rouge_noir_df\n",
    " .drop_duplicates('total_word_index')\n",
    " .groupby('full_word')\n",
    " .count()\n",
    " .sort_values(by='score', ascending=False)\n",
    ")['score'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe66d50-0bbb-4aed-9fe9-18d84468b45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-65cd5ac06478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcharacter_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/students/doyard/sentiment-evolution-in-characters-network/src/character_extraction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "from character_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_text =  get_book_text('798-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e474add9-6586-48ea-bda9-67893d695b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_pg_id = '798-8'\n",
    "book_luke_checkpoints_tmp_dir = f'../data/book_dfs/tmp/{book_pg_id}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca20dbc-ee67-4b19-9b45-3bf1432dda3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-large-finetuned-conll-2003 were not used when initializing LukeForEntitySpanClassification: ['luke.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LukeForEntitySpanClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeForEntitySpanClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 7929/7929 [57:17:02<00:00, 26.01s/it]       \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks_data/book_dfs/luke_798-8_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f047eddbc269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mluke_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_entities_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mluke_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'notebooks_data/book_dfs/luke_{book_pg_id}_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3385\u001b[0m         )\n\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3387\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks_data/book_dfs/luke_798-8_df.csv'"
     ]
    }
   ],
   "source": [
    "continue_from_ckpt = False\n",
    "\n",
    "if not continue_from_ckpt:\n",
    "    book_text, ner_entities_words = get_LUKE_person_entities(book_pg_id, \n",
    "                                                             book_luke_checkpoints_tmp_dir, \n",
    "                                                             ner_entities_words = [])\n",
    "    \n",
    "else:\n",
    "    # continue from checkpoint, if needed\n",
    "    latest_checkpoint = 10500\n",
    "    luke_df = pd.read_csv(f'{book_luke_checkpoints_tmp_dir}luke_tmp_df_{latest_checkpoint:05d}.csv')\n",
    "    ner_entities_checkpoint = [dict(zip(['full_word', 'sentence_word_index', 'total_word_index'], v)) \n",
    "                               for v in [tuple(r) for r in luke_df.to_numpy()]]\n",
    "\n",
    "    book_text, ner_entities_words = get_LUKE_person_entities(book_pg_id, \n",
    "                                                             book_luke_checkpoints_tmp_dir,\n",
    "                                                             last_checkpoint = latest_checkpoint,\n",
    "                                                             ner_entities_words = ner_entities_checkpoint)\n",
    "    \n",
    "luke_df = pd.DataFrame(ner_entities_words)\n",
    "luke_df.to_csv(f'notebooks_data/book_dfs/luke_{book_pg_id}_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e534b9b8-ff48-4b72-8463-29305a5a67b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_word_index</th>\n",
       "      <th>total_word_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Julien</th>\n",
       "      <td>1097</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathilde</th>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M. de Rênal</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme de Rênal</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M. de La Mole</th>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pirard</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valenod</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elle</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chélan</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme Derville</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle de La Mole</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norbert</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M. de Croisenois</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sorel</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M. de Frilair</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mais</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fouqué</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Altamira</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Mole</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korasoff</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslon</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de Rênal</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Derville</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Napoléon</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Élisa</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence_word_index  total_word_index\n",
       "full_word                                              \n",
       "Julien                           1097              1097\n",
       "Mathilde                          195               195\n",
       "M. de Rênal                       150               150\n",
       "Mme de Rênal                       82                82\n",
       "M. de La Mole                      73                73\n",
       "Pirard                             47                47\n",
       "Valenod                            40                40\n",
       "Elle                               40                40\n",
       "Chélan                             34                34\n",
       "Mme Derville                       30                30\n",
       "Mlle de La Mole                    26                26\n",
       "Norbert                            25                25\n",
       "M. de Croisenois                   22                22\n",
       "Sorel                              21                21\n",
       "M. de Frilair                      21                21\n",
       "Mais                               18                18\n",
       "Fouqué                             17                17\n",
       "Altamira                           15                15\n",
       "La Mole                            15                15\n",
       "Korasoff                           15                15\n",
       "Maslon                             13                13\n",
       "de Rênal                           12                12\n",
       "Derville                           12                12\n",
       "Napoléon                           11                11\n",
       "Élisa                              11                11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke_df.groupby('full_word').count().sort_values(by='total_word_index', ascending = False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f00bfd-7d5a-4330-8507-d82c92d9847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "luke_df.to_csv(f'../data/book_dfs/luke_{book_pg_id}_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7929/7929 [10:07<00:00, 13.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "full_word\n",
       "julien        1166\n",
       "rênal          595\n",
       "mathilde       340\n",
       "mole           170\n",
       "pirard         106\n",
       "abbé            81\n",
       "croisenois      53\n",
       "sorel           53\n",
       "derville        50\n",
       "norbert         49\n",
       "fervaques       38\n",
       "élisa           29\n",
       "valenod         28\n",
       "napoléon        27\n",
       "altamira        27\n",
       "caylus          27\n",
       "louis           24\n",
       "trouva          23\n",
       "chélan          21\n",
       "amanda          19\n",
       "geronimo        17\n",
       "frilair         16\n",
       "stanislas       16\n",
       "maslon          14\n",
       "don             14\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_noir_id = '798-8'\n",
    "(rouge_noir_text, \n",
    " rouge_noir_ent_tokens, \n",
    " rouge_noir_ent_words) = get_person_entities(rouge_noir_id, grouped_entities=False)\n",
    "\n",
    "# save entities into a dataframe, and to the disk\n",
    "red_black_df = pd.DataFrame(rouge_noir_ent_words)\n",
    "# rouge_noir_df['full_word'] =  rouge_noir_df['full_word'].apply(lambda s: s.lower())\n",
    "red_black_df.to_csv('../data/book_dfs/red_black_df.csv', index=False) \n",
    "\n",
    "# view top 25 entities\n",
    "(red_black_df\n",
    " .drop_duplicates('total_word_index')\n",
    " .groupby('full_word')\n",
    " .count()\n",
    " .sort_values(by='score', ascending=False)\n",
    ")['score'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from character_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbdd14cd-40c0-498b-8444-ca7dbdaecc8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/7929 [00:00<10:21, 12.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8c61ea6aa29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m (rouge_noir_text, \n\u001b[1;32m      3\u001b[0m  \u001b[0mrouge_noir_ent_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m  rouge_noir_ent_words) = get_person_entities(rouge_noir_id, grouped_entities=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# save entities into a dataframe, and to the disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/MA-4/Projet de Semestre/github/sentiment-evolution-in-characters-network/src/character_extraction.py\u001b[0m in \u001b[0;36mget_person_entities\u001b[0;34m(gutenberg_id, grouped_entities, max_chunk_len, split_chunk_len)\u001b[0m\n\u001b[1;32m    179\u001b[0m                                                                                             \u001b[0mner_entities_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                                                                             \u001b[0mner_entities_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                                                                                             \u001b[0msentence_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                                                                                             \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                                                                             \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/MA-4/Projet de Semestre/github/sentiment-evolution-in-characters-network/src/character_extraction.py\u001b[0m in \u001b[0;36mget_line_entities\u001b[0;34m(l, ner_entities_tokens, ner_entities_words, sentence_index, tokenizer, nlp, grouped_entities)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mnew_entity_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrouped_entities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mnew_entity_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'PER'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mnew_entity_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'PER'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/token_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/token_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         return {\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         outputs = self.mobilebert(\n\u001b[0m\u001b[1;32m   1563\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         )\n\u001b[0;32m--> 874\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    556\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         outputs = (\n\u001b[1;32m    519\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, intermediate_states, residual_tensor_1, residual_tensor_2)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual_tensor_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_tensor_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, residual_tensor)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rouge_noir_id = '798-8'\n",
    "(rouge_noir_text, \n",
    " rouge_noir_ent_tokens, \n",
    " rouge_noir_ent_words) = get_person_entities(rouge_noir_id, grouped_entities=True)\n",
    "\n",
    "# save entities into a dataframe, and to the disk\n",
    "rouge_noir_df = pd.DataFrame(rouge_noir_ent_words)\n",
    "# rouge_noir_df['full_word'] =  rouge_noir_df['full_word'].apply(lambda s: s.lower())\n",
    "rouge_noir_df.to_csv('../data/book_dfs/798-8.csv', index=False) \n",
    "\n",
    "# view top 25 entities\n",
    "(rouge_noir_df\n",
    " .drop_duplicates('total_word_index')\n",
    " .groupby('full_word')\n",
    " .count()\n",
    " .sort_values(by='score', ascending=False)\n",
    ")['score'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed50738-07c8-4e35-b323-4bfc1e65825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eloisedoyard/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "from character_extraction import *\n",
    "from embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590c063e-fa98-4af6-9b72-f37c664b69cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de Verrières peut passer pour l\n",
      "oublier au voyageur l' atmosphère\n",
      "voisins. Les jardins de M\n",
      "de la_ manie de propriétaire\n",
      "mauvaise tête_ , et il\n",
      "qu' aux États- Unis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3715/3715 [00:00<00:00, 251709.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de Verrières peut passer pour l',\n",
       " \"oublier au voyageur l' atmosphère\",\n",
       " 'voisins. Les jardins de M',\n",
       " 'de la_ manie de propriétaire',\n",
       " 'mauvaise tête_ , et il',\n",
       " \"qu' aux États- Unis\",\n",
       " 'en cascade, on les voit',\n",
       " 'la promenade de plus de six',\n",
       " 'retiré à Verrières, et qui',\n",
       " \"j' aime l' ombre\",\n",
       " 'plus des trois quarts des habitants',\n",
       " 'de la Fidélité, donnant le',\n",
       " 'la Fidélité, donnant le bras',\n",
       " 'Rênal paraissait une femme de trente',\n",
       " 'paraissait une femme de trente ans',\n",
       " 'Paris, disait M. de',\n",
       " \"de mendicité. C' était\",\n",
       " 'Je suis vieux et aimé ici',\n",
       " 'suite vers le monsieur de Paris',\n",
       " 'pas la moindre marque de blâme',\n",
       " 'inspection du dépôt de mendicité ,',\n",
       " 'le curé, que ce voyageur',\n",
       " 'à regret la crainte du bâton',\n",
       " 'M. le curé, j',\n",
       " 'une voix de plus en plus',\n",
       " 'le geôlier; vous, M',\n",
       " ', commentés, exagérés de vingt',\n",
       " 'leurs paroles. -- Eh',\n",
       " \"j' ai marié les grands\",\n",
       " \". On sait qu' il\",\n",
       " 'quand on parle de me la',\n",
       " 'cri. Le second de ses',\n",
       " 'petit événement changea le cours de',\n",
       " 'mettre en pension chez les Sorel',\n",
       " 'bien à son asthme; mais',\n",
       " 'sa femme, par un sourire',\n",
       " 'eût appris ce genre de succès',\n",
       " 'appris ce genre de succès ,',\n",
       " 'ce genre de succès, Mme',\n",
       " 'avec un visage coloré et de',\n",
       " 'visage coloré et de gros favoris',\n",
       " 'ville venir moins chez elle .',\n",
       " 'âme naïve, qui jamais ne',\n",
       " 'oncle. Le vieux capitaine de',\n",
       " '. Le vieux capitaine de Rênal',\n",
       " ', Se cosi è? MACHIAVELLI',\n",
       " 'père Sorel. Quoique je le',\n",
       " '- t- il la soutane',\n",
       " 't- il la soutane ?',\n",
       " '- il la soutane? M',\n",
       " 'plus content de la singulière proposition',\n",
       " 'content de la singulière proposition que',\n",
       " 'bien se revêtir la finesse des',\n",
       " 'abord que la longue récitation de',\n",
       " \", l' esprit actif du\",\n",
       " 'M. de Rênal lui offrait',\n",
       " \"de sapin, qu' ils\",\n",
       " \"sapin, qu' ils allaient\",\n",
       " \". Ils n' entendirent pas\",\n",
       " \"n' entendirent pas la voix\",\n",
       " 'pas la voix de leur père',\n",
       " 'la voix de leur père .',\n",
       " 'Celui- ci se dirigea vers',\n",
       " 'Julien deux ou trois fois .',\n",
       " \"empêcha d' entendre la terrible\",\n",
       " 'sur la poutre transversale qui soutenait',\n",
       " 'la poutre transversale qui soutenait le',\n",
       " 'douleur physique, que pour la',\n",
       " ', que pour la perte de',\n",
       " \"' entendre cet ordre. Son\",\n",
       " 'alla chercher une longue perche pour',\n",
       " 'le plus, _ le Mémorial',\n",
       " 'plantés fort bas, lui donnaient',\n",
       " 'petit front, et, dans',\n",
       " 'front, et, dans les',\n",
       " '. Une taille svelte et bien',\n",
       " 'Une taille svelte et bien prise',\n",
       " 'son air extrêmement pensif et sa',\n",
       " \"' il vivrait pour être une\",\n",
       " 'pour être une charge à sa',\n",
       " 'un être faible, Julien avait',\n",
       " 'se trouvèrent en face des petits',\n",
       " \"et ma scie n' en\",\n",
       " 'de se laisser réduire à manger',\n",
       " \"père voudra m' y forcer\",\n",
       " \"Confessions de Rousseau. C '\",\n",
       " 'à son fils. M .',\n",
       " \"Sorel, d' un ton\",\n",
       " \", d' un ton de\",\n",
       " \"d' un ton de voix\",\n",
       " 'donnerez. -- Comment !',\n",
       " 'à lui, et, après',\n",
       " ', et, après une conversation',\n",
       " 'un mot ne fut dit au',\n",
       " 'existence de Julien, se trouvèrent',\n",
       " 'fit des progrès. Jamais il',\n",
       " '. M. de Rênal vint',\n",
       " 'M. de Rênal vint à',\n",
       " ', il se retira. Sa',\n",
       " ', maudit paresseux, lui dit',\n",
       " 'avec transport les récits des batailles',\n",
       " 'entre le juge de paix et',\n",
       " '. Le juge de paix fut',\n",
       " 'un différend avec un prêtre ,',\n",
       " 'entrefaites, le juge de paix',\n",
       " 'un si honnête homme! Le',\n",
       " 'pas une heure de sa vie',\n",
       " 'militaire était nécessaire et à la',\n",
       " 'lia le bras droit contre la',\n",
       " 'peine afflictive, il se pardonna',\n",
       " 'eût tout au plus donné dix',\n",
       " 'tout au plus donné dix -',\n",
       " 'le banc qui avait la plus',\n",
       " '_- - Qui a pu',\n",
       " 'armes! Ce mot, si',\n",
       " '! Ce mot, si souvent',\n",
       " 'personne dont le coeur fût troublé',\n",
       " 'précepteur. Ce fut en vain',\n",
       " 'était loin des regards des hommes',\n",
       " 'venait demander quelque grâce à M',\n",
       " \"' approcha, distraite un instant\",\n",
       " 'étaient arrêtées sur les joues si',\n",
       " \"s' était figuré comme un\",\n",
       " 'un prêtre sale et mal vêtu',\n",
       " 'enfants? -- Moi ,',\n",
       " \"? S' entendre appeler de\",\n",
       " 'tête dans le bassin de la',\n",
       " \"' une jeune fille à ce\",\n",
       " 'ne tomberaient pas dans les mains',\n",
       " \"l' air fort méchant ;\",\n",
       " 'approcha et lui dit à mi',\n",
       " \"air mâle que l' on\",\n",
       " 'son père a voulu le battre',\n",
       " 'père a voulu le battre ;',\n",
       " 'qui se connaissait fort bien en',\n",
       " 'connaissait fort bien en beauté féminine',\n",
       " 'peu encouragé par ce mot de',\n",
       " 'adressait deux ou trois mots d',\n",
       " 'la porter à ses lèvres .',\n",
       " 'chaud, son bras était tout',\n",
       " 'son bras était tout à fait',\n",
       " 'je vous parle avant que les',\n",
       " 'qui voulait les laisser seuls .',\n",
       " 'que vous ne voyiez plus ni',\n",
       " \"j' exige votre parole de\",\n",
       " 'Maintenant, _ monsieur_ ,',\n",
       " 'le monde ici va vous appeler',\n",
       " \"l' ont- il aperçu\",\n",
       " 'homme surpris, en lui donnant',\n",
       " 'la présence de Julien, en',\n",
       " 'et il avait tant envie de',\n",
       " 'envie de cacher sa joie ,',\n",
       " 'avec des yeux étonnés. -',\n",
       " 'Mme de Rênal déguisa la vérité',\n",
       " \"une centaine de francs qu '\",\n",
       " \". Les enfants auxquels l '\",\n",
       " 'hasard, continua Julien, et',\n",
       " ', continua Julien, et dites',\n",
       " 'la même facilité. - -',\n",
       " \"je me destine m' a\",\n",
       " 'un assez grand nombre de prétendus',\n",
       " \"' il disait. Ils regardaient\",\n",
       " 'Stanislas, tout fier, lut',\n",
       " ', tout fier, lut tant',\n",
       " 'que mal le premier mot d',\n",
       " '. de Rênal lui- même',\n",
       " \", s' écria- t\",\n",
       " \"on dirait que c' est\",\n",
       " \"dirait que c' est la\",\n",
       " 'tout sanglant. Mme de Rênal',\n",
       " 'sanglant. Mme de Rênal ,',\n",
       " '. Mme de Rênal, se',\n",
       " 'mort. Son saisissement fut tel',\n",
       " 'premier écueil qui avait failli arrêter',\n",
       " \"remarqua qu' il parlait plus\",\n",
       " \"' eût pas remarquée avant l\",\n",
       " 'choquée. Mme de Rênal était',\n",
       " \", que l' on peut\",\n",
       " ', la plupart du temps ,',\n",
       " \"_, et animées d '\",\n",
       " \", et animées d' une\",\n",
       " 'manière de vivre tout intérieure .',\n",
       " ', citée à cause de son',\n",
       " \"eu d' attention que pour\",\n",
       " \"' attention que pour ses enfants\",\n",
       " \"accès de fièvre d' un\",\n",
       " 'de ce genre de chagrins ,',\n",
       " 'empressées et mielleuses du couvent jésuitique',\n",
       " 'passé sa jeunesse. Son éducation',\n",
       " 'jeunesse. Son éducation fut faite',\n",
       " 'Rênal lui eut bientôt pardonné son',\n",
       " 'lui eut bientôt pardonné son ignorance',\n",
       " 'plus communes, même quand il',\n",
       " 'pauvre chien écrasé, comme il',\n",
       " \"' humanité lui semblèrent peu à\",\n",
       " 'et ce modèle, tôt ou',\n",
       " \"est qu' ambitieux parce que\",\n",
       " \"' ambitieux parce que la délicatesse\",\n",
       " 'romans des exemples de conduite .',\n",
       " \"singulière à Julien. C '\",\n",
       " \"première fois qu' elle l\",\n",
       " 'Elle ralentit le pas. -',\n",
       " '.. si étonnants. .',\n",
       " 'que je voudrais vous prier d',\n",
       " 'marque de ma reconnaissance. Il',\n",
       " 'quelques louis pour vous faire du',\n",
       " 'pour vous faire du linge .',\n",
       " 'rougissant encore plus, et elle',\n",
       " 'et elle cessa de parler .',\n",
       " 'baissant la tête, de parler',\n",
       " '- Je suis petit, madame',\n",
       " \"sa hauteur, c' est\",\n",
       " \"' habite sa maison; je\",\n",
       " ', Mme de Rênal était restée',\n",
       " 'Mme de Rênal était restée pâle',\n",
       " \"termina sans que ni l '\",\n",
       " ', reprit M. de Rênal',\n",
       " \"' a donné cent francs .\",\n",
       " 'comme incertaine. -- Donnez',\n",
       " 'Là, elle choisit pour dix',\n",
       " 'donna à ses fils. Mais',\n",
       " 'ses fils. Mais ces livres',\n",
       " 'celui- ci était étonné de',\n",
       " '- ci était étonné de la',\n",
       " \"avec de l' adresse ,\",\n",
       " 'dans la province. Après un',\n",
       " 'à un tel point, que',\n",
       " \"continua Julien, d' un\",\n",
       " 'pourrait faire prendre un abonnement chez',\n",
       " 'il avait été toute sa vie',\n",
       " 'Le plaisant, avec tant d',\n",
       " 'que souvent il ne comprenait absolument',\n",
       " 'il ne comprenait absolument rien à',\n",
       " 'homme doit dire quand il est',\n",
       " 'dire quand il est seul avec',\n",
       " 'par les souffrances les plus cruelles',\n",
       " 'arrivait de dire les choses les',\n",
       " 'les plus ridicules. Pour comble',\n",
       " 'plus ridicules. Pour comble de',\n",
       " \"il n' arrivait jamais à\",\n",
       " \"n' arrivait jamais à dire\",\n",
       " \"' arrivait jamais à dire quelque\",\n",
       " 'sévèrement bannie des moeurs de la',\n",
       " 'ignorance, Mme de Rênal ,',\n",
       " 'que vous ne vous fassiez pas',\n",
       " 'vous ne vous fassiez pas d',\n",
       " \"ne vous fassiez pas d '\",\n",
       " 'de prêtre. Si vous songez',\n",
       " \"s' appelle savoir- vivre\",\n",
       " 'incompatible avec le salut, mais',\n",
       " \"Pourquoi l' état où je\",\n",
       " \"' être prêtre, et cela\",\n",
       " 'Trois jours après, Julien avait',\n",
       " 'dû se munir dès le premier',\n",
       " \"à un tiers, l '\",\n",
       " \"tiers, l' avait détourné\",\n",
       " 'ces nouvelles remontrances, fort bien',\n",
       " 'eût employés un jeune séminariste fervent',\n",
       " 'et aux gestes, il vivait',\n",
       " 'privé de la vue des grands',\n",
       " 'lui parla de son mariage .',\n",
       " 'Mme de Rênal crut sincèrement qu',\n",
       " 'Élisa redoublèrent; elle lui dit',\n",
       " 'malheur. -- Dites répondit',\n",
       " \"' un charpentier; lui -\",\n",
       " \"et la fortune d' Élisa\",\n",
       " 'Elle était profondément étonnée. Aurais',\n",
       " ', jamais cette bonne provinciale n',\n",
       " 'planté de pommiers servait de promenade',\n",
       " 'bout du verger; leur feuillage',\n",
       " '- vingts pieds de hauteur .',\n",
       " ', le blé ne peut venir',\n",
       " 'le blé ne peut venir sous',\n",
       " 'blé ne peut venir sous leur',\n",
       " 'arrivée à Vergy M. de',\n",
       " 'des ouvriers à ses frais .',\n",
       " 'ce qui le consolait un peu',\n",
       " 'grands capuchons de gaze claire ,',\n",
       " 'capuchons de gaze claire, avec',\n",
       " 'de gaze claire, avec lesquels',\n",
       " 'se parlaient sans cesse, et',\n",
       " 'se mettre lui allait à ravir',\n",
       " 'dîner à Vergy. ( C',\n",
       " 'de Rênal se livrait à tant',\n",
       " 'avec Élisa à bâtir des robes',\n",
       " \"l' envie d' acheter\",\n",
       " \". Dès l' arrivée de\",\n",
       " 'pic, que Julien, heureux',\n",
       " 'gâté aux yeux de Julien les',\n",
       " 'de ces souvenirs amers; pour',\n",
       " ', il venait dans ces rochers',\n",
       " \"' habitude de passer les soirées\",\n",
       " \"Julien pensa qu' il était\",\n",
       " \"_ devoir_ d' obtenir\",\n",
       " \", et d' un ridicule\",\n",
       " \"' on n' y parvenait\",\n",
       " \"on n' y parvenait pas\",\n",
       " 'SOIRÉE A LA CAMPAGNE La Didon',\n",
       " 'A LA CAMPAGNE La Didon de',\n",
       " 'LA CAMPAGNE La Didon de M',\n",
       " \"étaient singuliers; il l '\",\n",
       " 'firent perdre la tête à Mme',\n",
       " 'permettait à Julien de moins parler',\n",
       " \"de sonner à l' horloge\",\n",
       " \"qu' il prenait, il\",\n",
       " 'renouvelait la proposition de rentrer au',\n",
       " \"fortement la main qu' on\",\n",
       " ': il parla, il oublia',\n",
       " 'salon. Alors il serait resté',\n",
       " 'touchants et emphatiques trouvèrent grâce devant',\n",
       " 'rien; elle se laissait vivre',\n",
       " 'tradition du pays dit planté par',\n",
       " 'épais feuillage du tilleul, et',\n",
       " 'de fleurs que le vent venait',\n",
       " \"c' eût été entre eux\",\n",
       " 'Le bonheur lui ôtait le sommeil',\n",
       " 'eût su, à peine lui',\n",
       " 'lecture des exploits de son héros',\n",
       " 'les bulletins de la grande armée',\n",
       " 'mécontentement de ce que Julien passait',\n",
       " \"attention jusqu' à écouter les\",\n",
       " 'lui adressait M. de Rênal',\n",
       " 'Julien en le chassant à l',\n",
       " \"maxime qu' il s '\",\n",
       " \"' il s' était faite\",\n",
       " '- voix: -- _',\n",
       " 'paysanne qui avait pris un sentier',\n",
       " 'avait pris un sentier abusif ,',\n",
       " 'yeux où se peignait le plus',\n",
       " 'où se peignait le plus souverain',\n",
       " \"Après les progrès étonnants qu '\",\n",
       " 'allait éclater. Heureusement M .',\n",
       " '. Heureusement M. de Rênal',\n",
       " \"la promenade il fut l '\",\n",
       " \"promenade il fut l' objet\",\n",
       " \"il fut l' objet .\",\n",
       " \"Ah! comme je l '\",\n",
       " 'force de parler pour parler ,',\n",
       " ', avec un de ses fermiers',\n",
       " 'avec un de ses fermiers .',\n",
       " \"' est avec de la paille\",\n",
       " 'est avec de la paille de',\n",
       " ', ajouta Mme de Rênal ;',\n",
       " '-- Sauvez- moi la',\n",
       " \"madame, que j' ai\",\n",
       " \"que j' ai un portrait\",\n",
       " 'dans ce moment entrer dans ma',\n",
       " 'ai une seconde grâce à vous',\n",
       " 'grâce à vous demander, madame',\n",
       " 'vous demander, madame je vous',\n",
       " \"- C' est un secret\",\n",
       " \"seul intérêt d' argent ,\",\n",
       " 'déjà mis de la générosité dans',\n",
       " 'générosité dans cette âme. Cruellement',\n",
       " 'en doublant le pas. Elle',\n",
       " \"' antichambre de cet appartement ,\",\n",
       " 'était pâle, anéanti, il',\n",
       " \"' exagérait l' étendue du\",\n",
       " 'tête, trouvé caché chez un',\n",
       " 'carton blanc derrière le portrait des',\n",
       " 'en voyant brûler la boîte et',\n",
       " 'voyant brûler la boîte et ma',\n",
       " 'sentait pour lui- même le',\n",
       " 'pour lui- même le disposaient',\n",
       " 'Mme de Rênal et prit sa',\n",
       " \"de Rênal qu' une femme\",\n",
       " 'cet homme fut pour Julien la',\n",
       " \"pour Julien la goutte d '\",\n",
       " 'arrêta et regarda ses domestiques .',\n",
       " 'à dix pas occupés à arranger',\n",
       " ', lui dit- il enfin',\n",
       " 'regarder M. de Rênal ,',\n",
       " '. Voilà cent soixante- huit',\n",
       " 'se retrouva vis- à -',\n",
       " 'quelques heures. -- Eh',\n",
       " '- Eh, mon cher Julien',\n",
       " \"; il ne m' a\",\n",
       " 'lequel une heure auparavant il était',\n",
       " 'bouillant de colère, acheva de',\n",
       " 'roc immense et bien sûr d',\n",
       " \"lui peignait la position qu '\",\n",
       " \"la position qu' il brûlait\",\n",
       " 'ses chiens, ses enfants et',\n",
       " 'pénibles recherches. Julien, debout',\n",
       " \"immenses. L' oeil de\",\n",
       " 'pourtant paraître à Verrières. En',\n",
       " 'paraître à Verrières. En sortant',\n",
       " '. De retour à Vergy Julien',\n",
       " \"émotions puissantes qui l' avaient\",\n",
       " 'agité dans cette journée, Que',\n",
       " 'et même pour son amie ,',\n",
       " 'même pour son amie, et',\n",
       " \"tour, ne comprenait qu '\",\n",
       " 'lui disaient. Tel était l',\n",
       " 'hésita un peu, mais on',\n",
       " 'un peu, mais on finit',\n",
       " \"Rênal qui s' approchait .\",\n",
       " ', que de prendre possession de',\n",
       " 'il désira avec anxiété, et',\n",
       " 'Rênal parlait politique avec colère :',\n",
       " 'sa chaise de celle de Mme',\n",
       " 'chaise de celle de Mme de',\n",
       " 'Mme de Rênal frémit. Son',\n",
       " 'pas; elle se hâta de',\n",
       " \"l' avait fait réfléchir .\",\n",
       " 'les sentiments que je puis avoir',\n",
       " 'donc, se dit- elle',\n",
       " '? Elle fut effrayée; ce',\n",
       " \", la présence d' un\",\n",
       " \"présence d' un bonheur que\",\n",
       " \"n' avait même rêvé lui\",\n",
       " 'Julien né pensait plus à sa',\n",
       " 'suite, lui laissait quelque repos',\n",
       " \"dans l' idée horrible que\",\n",
       " 'portrait, ou de la compromettre',\n",
       " \"il ne s' était montré\",\n",
       " \"douleur arriva à toute l '\",\n",
       " 'auprès de son lit la clarté',\n",
       " 'à ce mot singulier. Mme',\n",
       " 'par la nécessité de se contraindre',\n",
       " \"reprit l' empire que l\",\n",
       " \"l' empire que l '\",\n",
       " 'de la voix de cette fille',\n",
       " 'la voix de cette fille ,',\n",
       " 'à caractère. SIEYES. Le',\n",
       " 'Elle le regardait. Enfin ,',\n",
       " 'le regardait. Enfin, malgré',\n",
       " 'de charmes à cette figure céleste',\n",
       " \"il n' y eut plus\",\n",
       " \"' y eut plus sur sa\",\n",
       " 'un sot, se dit -',\n",
       " 'qui est en commerce avec leur',\n",
       " 'richesse; mais que mon coeur',\n",
       " '; mais que mon coeur est',\n",
       " 'dédain ou de faveur. Pendant',\n",
       " 'ou de faveur. Pendant que',\n",
       " \"en foule dans l' âme\",\n",
       " 'par toute la surprise du changement',\n",
       " 'troublé par aucune passion, trouva',\n",
       " 'par aucune passion, trouva bien',\n",
       " 'aucune passion, trouva bien vite',\n",
       " 'partit. Comme elle le regardait',\n",
       " 'accourait du fond du jardin ,',\n",
       " 'résister à cet amant si aimable',\n",
       " 'à cet amant si aimable ,',\n",
       " 'si aimable, mais de le',\n",
       " \"le hasard l' avait engagée\",\n",
       " 'la vallée du Doubs. Bientôt',\n",
       " \"' arrêter de temps à autre\",\n",
       " 'grande montagne, près duquel il',\n",
       " '. Il prit sa course ,',\n",
       " \"' entourait. Il remarqua enfin\",\n",
       " \"son âme s' égarait dans\",\n",
       " \"se séparait d' elle pour\",\n",
       " \"disparu avec l' espoir d\",\n",
       " \"avec l' espoir d '\",\n",
       " '. Valenod, le sous -',\n",
       " '- là; te voilà en',\n",
       " \"tout le monde me l '\",\n",
       " 'la plus haute idée des lumières',\n",
       " 'où je suis de tant de',\n",
       " 'tous ces hommes de salon .',\n",
       " 'de fonds à verser dans son',\n",
       " '- je mon ami? s',\n",
       " \"s' écria Julien avec humeur\",\n",
       " \"' écria Julien avec humeur .\",\n",
       " 'salut, ne put cette fois',\n",
       " \"homme qui l' aimait .\",\n",
       " \"répondit d' un grand sang\",\n",
       " 'fournis de bois à brûler M',\n",
       " ', mais jamais argent ne fut',\n",
       " ', cette main! quel charme',\n",
       " 'cette main! quel charme !',\n",
       " 'dans la montagne. Il fut',\n",
       " 'seule distraction de Mme de Rênal',\n",
       " \", une robe d' été\",\n",
       " 'de Rênal la mit aussitôt .',\n",
       " 'du jeune précepteur. Mme de',\n",
       " 'reproche son orgueil, et dès',\n",
       " 'a aussi des devoirs envers soi',\n",
       " 'ces mots aristocratiques que Julien avait',\n",
       " \"s' anima d' un\",\n",
       " \"' homme étonnant que son mari\",\n",
       " \"que l' on comprît rien\",\n",
       " \"l' on comprît rien aux\",\n",
       " \"compliment de la réputation qu '\",\n",
       " 'il avait conquise, et l',\n",
       " 'il eût été pour elle doux',\n",
       " \", bien loin d' augmenter\",\n",
       " 'nuit; à peine fut -',\n",
       " 'Il pensait à la hardiesse dont',\n",
       " 'Rênal; le mot bien nés',\n",
       " '; le mot bien nés pesait',\n",
       " \"l' âme de cette pauvre\",\n",
       " \"par le rang d' un\",\n",
       " 'Julien répondit en soupirant: -',\n",
       " \"Mme de Rênal s' appuya\",\n",
       " \"de l' amour; quand\",\n",
       " \"' accorderai rien à Julien se\",\n",
       " \"; il ne pouvait s '\",\n",
       " \"s' arrêter à aucun parti\",\n",
       " 'Heureusement pour lui, même dans',\n",
       " \"Je lui trouve l' air\",\n",
       " 'M. Charcot de Maugiron ,',\n",
       " 'tomber ses ciseaux, son peloton',\n",
       " 'put passer pour une tentative gauche',\n",
       " 'pour une tentative gauche destinée à',\n",
       " 'de bien sottes manières! pensa',\n",
       " \"chose de relatif à l '\",\n",
       " 'des enfants, mais en répondant',\n",
       " 'amour. Fait les égalités et',\n",
       " 'allait à Verrières voir le curé',\n",
       " 'Verrières voir le curé, il',\n",
       " \"voir un tel exemple d '\",\n",
       " \"prudence l' emportait sur l\",\n",
       " 'Mme Derville, et que probablement',\n",
       " 'il se sentait tellement troublé qu',\n",
       " \"la porte d' une main\",\n",
       " 'Mme de Rênal se jeta vivement',\n",
       " 'ses vains projets et revint à',\n",
       " 'genoux. Comme elle lui parlait',\n",
       " 'avec une extrême dureté, il',\n",
       " \"efforts d' attention incroyables pour\",\n",
       " 'mettre du rouge. Mortellement effrayée',\n",
       " 'de Julien, Mme de Rênal',\n",
       " 'à lui refuser, elle repoussait',\n",
       " 'avec une indignation réelle, et',\n",
       " 'ce que ça? Telle fut',\n",
       " 'Ah! beaucoup dans ce moment',\n",
       " 'et ses efforts pour le cacher',\n",
       " 'Rênal; il ne lui ôta',\n",
       " 'si bien les choses, qu',\n",
       " \"choses, qu' elle se\",\n",
       " 'elle vint coller son oreille contre',\n",
       " 'de son amie, car il',\n",
       " 'son âge contribua à lui donner',\n",
       " ', à cause de sa naissance',\n",
       " 'Julien rassuraient sa timide maîtresse ,',\n",
       " ', elle reprenait un peu de',\n",
       " 'de son attention à jouer un',\n",
       " 'découverte lui eût à jamais enlevé',\n",
       " \"' âge est, après celle\",\n",
       " 'communs de la plaisanterie de province',\n",
       " \"disait- il, qu '\",\n",
       " \"- il, qu' elle\",\n",
       " 'rôle à jouer. Dans un',\n",
       " 'à jouer. Dans un moment',\n",
       " \"l' interroger sur le portrait\",\n",
       " \"' intérêt; Julien lui jura\",\n",
       " 'elle ne revenait pas de son',\n",
       " 'fût doutée. Ah! se',\n",
       " 'doutée. Ah! se disait',\n",
       " '. Ah! se disait -',\n",
       " \"l' ambition: c '\",\n",
       " ', lui pauvre être si malheureux',\n",
       " '. Il ouvrait son armoire de',\n",
       " \"' un mariage, emplissent une\",\n",
       " \"sa maîtresse semblait l' élever\",\n",
       " \"Julien se livrait d' autant\",\n",
       " \"moments où lui qui n '\",\n",
       " \"lui qui n' avait jamais\",\n",
       " 'now shows all the beauty of',\n",
       " 'homme envoyé de Dieu pour les',\n",
       " 'ne vous mêlez plus à ces',\n",
       " 'vous mêlez plus à ces gens',\n",
       " 'mêlez plus à ces gens -',\n",
       " \"échec porté à l' illusion\",\n",
       " \"porté à l' illusion qui\",\n",
       " 'sur le point de devenir durable',\n",
       " 'du mot de Julien parce que',\n",
       " 'ses inconvénients. Julien avait reçu',\n",
       " 'attente, la veille encore de',\n",
       " \"verger, l' eût mis\",\n",
       " \"les livres d' une façon\",\n",
       " \"d' une façon toute nouvelle\",\n",
       " \"dont l' ignorance arrête tout\",\n",
       " 'veuille lui supposer. Cette éducation',\n",
       " 'il y a deux mille ans',\n",
       " 'Besançon. Elles étaient appuyées par',\n",
       " 'libéraux ne soupçonnaient pas même la',\n",
       " 'royale. Or, si M',\n",
       " \"' il y a de mieux\",\n",
       " 'Rênal donnait un ordre au valet',\n",
       " 'autrefois, et récemment rendu au',\n",
       " \"; les femmes n' y\",\n",
       " \"qu' un jour ils ne\",\n",
       " '. Le souvenir des charmes de',\n",
       " \"avec des yeux étincelants d '\",\n",
       " \"savante, à l' occasion\",\n",
       " \"simples qu' un enfant bien\",\n",
       " \"veines n' ont plus de\",\n",
       " '- Clément. Le 3 septembre',\n",
       " '. Le 3 septembre à dix',\n",
       " 'que Sa majesté le roi de',\n",
       " \"garde d' honneur; il\",\n",
       " '. Chacun avait ses prétentions ;',\n",
       " 'la place de premier adjoint .',\n",
       " 'place de premier adjoint. Il',\n",
       " 'de premier adjoint. Il n',\n",
       " 'rien à dire à la dévotion',\n",
       " 'avis comme si déjà vous occupiez',\n",
       " \"dans la garde d' honneur\",\n",
       " \"garde d' honneur. L\",\n",
       " 'maison. Tout ce tapage l',\n",
       " \"parler. Elle s' enfuit\",\n",
       " \"refusant de l' écouter .\",\n",
       " \"' était davantage: un de\",\n",
       " 'ou six jeunes gens, fils',\n",
       " ', qui avaient brillé sept ans',\n",
       " 'elle trouvait imprudent de faire faire',\n",
       " \"de l' esprit public terminé\",\n",
       " \"le maire eut à s '\",\n",
       " \"eut à s' occuper d\",\n",
       " 'la ville. On désirait un',\n",
       " \"' administration de Verrières à recevoir\",\n",
       " 'administration de Verrières à recevoir un',\n",
       " 'affront de M. de La',\n",
       " ', moqueur, ne cherchant qu',\n",
       " 'du samedi au dimanche, après',\n",
       " 'des montagnes voisines inondèrent les rues',\n",
       " 'son de toutes les cloches ,',\n",
       " 'chaque instant la main prudente était',\n",
       " 'parce que ce petit ouvrier déguisé',\n",
       " 'En général on rendait justice à',\n",
       " 'général on rendait justice à son',\n",
       " \"plus brillantes, parce qu '\",\n",
       " 'il ne tomba pas; de',\n",
       " \"' abord elle l' avait\",\n",
       " \"la garde d' honneur à\",\n",
       " 'rétablie depuis la Restauration, et',\n",
       " 'lui remit une soutane et un',\n",
       " 'impatientait. Il attendait son chef',\n",
       " 'il était convenable que M .',\n",
       " 'il rencontrait. Une fort petite',\n",
       " 'rencontrait. Une fort petite céda',\n",
       " 'Monseigneur, en habit noir et',\n",
       " 'en habit noir et la chaîne',\n",
       " ', étaient garnis de stalles de',\n",
       " 'plâtre encore tout blanc, toucha',\n",
       " \"avait l' air irrité ;\",\n",
       " 'dentelles arrêta involontairement Julien à quelques',\n",
       " 'dans la psyché, se retourna',\n",
       " \"recommandé, dit l' évêque\",\n",
       " \"' enchantement de Julien. Mais\",\n",
       " 'de Julien. Mais je vous',\n",
       " 'Votre Grandeur le permet. Les',\n",
       " 'porter: en traversant la salle',\n",
       " '.- - Ah! elle',\n",
       " \". Julien était immobile d '\",\n",
       " ', Monseigneur. -- Elle',\n",
       " 'pas aperçue. Mais cette fois',\n",
       " 'exquise de ce prélat se disputaient',\n",
       " 'de ces manières charmantes. On',\n",
       " 'roi entra. Julien eut le',\n",
       " 'de La Mole, qui avait',\n",
       " 'Mole, qui avait fait avoir',\n",
       " 'du roi, qui réellement priait',\n",
       " \", suivant l' expression de\",\n",
       " \"c' était M. de\",\n",
       " \"' était M. de La\",\n",
       " 'son voisin, lui apprit que',\n",
       " '. Mais en se mettant en',\n",
       " 'la porte, étaient réunies à',\n",
       " 'porte, étaient réunies à genoux',\n",
       " ', étaient réunies à genoux vingt',\n",
       " \"nu d' une jeune fille\",\n",
       " \"d' Agde demanda au roi\",\n",
       " \", d' un air inspiré\",\n",
       " \"demoiselles qui l' avaient accompagnée\",\n",
       " 'distribuer aux paysans dix mille bouteilles',\n",
       " 'une visite à M. de',\n",
       " 'une feuille de papier très fort',\n",
       " 'au bas de la première page',\n",
       " 'cuisinière. « Monsieur le marquis',\n",
       " '« Monsieur le marquis, »',\n",
       " \"générale, et j' ose\",\n",
       " \", et j' ose dire\",\n",
       " 'à Monsieur le marquis le bureau',\n",
       " 'cet imbécile de Cholin me montre',\n",
       " 'peintes, qui, soir et',\n",
       " \"' une façon suivie, elle\",\n",
       " 'Sacré- Coeur elle avait aimé',\n",
       " \"dès qu' ils se trouvaient\",\n",
       " \"qu' ils se trouvaient seuls\",\n",
       " 'tête que pour apaiser la colère',\n",
       " 'que pour apaiser la colère du',\n",
       " 'nom de Dieu, quittez cette',\n",
       " 'à voix basse, il est',\n",
       " 'tue; voilà de la grandeur',\n",
       " 'je pu inspirer un tel amour',\n",
       " 'façons? Une nuit, l',\n",
       " 'ne put reconnaître son père .',\n",
       " 'reconnaître son père. Tout à',\n",
       " 'ai donné la vie, et',\n",
       " 'vie, et je la lui',\n",
       " \"homme d' imagination, il\",\n",
       " \"Idées romanesques, s' écria\",\n",
       " 'médecin à la pointe du jour',\n",
       " 'ans, pour ne plus bouger',\n",
       " \"sait de l' homme ;\",\n",
       " \"mérites de l' être .\",\n",
       " 'scandale. On te donnera tous',\n",
       " ', en se levant debout .',\n",
       " 'se levant debout. Je souffrirai',\n",
       " 'dans la fange; et ,',\n",
       " 'la fange; et, par',\n",
       " \"elle, après s' être\",\n",
       " 'que comme un frère? C',\n",
       " 'est la seule expiation raisonnable ;',\n",
       " 'frère? Julien fondait en larmes',\n",
       " ', le ciel quand elle était',\n",
       " \"elle dans d' autres moments\",\n",
       " \"vue d' un sacrifice si\",\n",
       " 'chaque instant. Il adorait Mme',\n",
       " 'dans ses incertitudes mortelles. -',\n",
       " 'peut- être, je ne',\n",
       " 'transports pleins de folie. Leur',\n",
       " 'monde. Mais ils ne retrouvèrent',\n",
       " '. Mais ils ne retrouvèrent plus',\n",
       " 'quelques jours à passer avec lui',\n",
       " \"l' avaient tant de fois\",\n",
       " 'tant de fois fait rougir ,',\n",
       " 'parler au précepteur! Dès le',\n",
       " 'le vit pâlir en lisant cette',\n",
       " 'duquel il lut ces mots écrits',\n",
       " \"ne m' aurais- tu\",\n",
       " \"' aurais- tu jamais aimée\",\n",
       " 'seras un monstre. Ne m',\n",
       " ', montre cette lettre dans tout',\n",
       " 'ne prononce pas un tel blasphème',\n",
       " 'prononce pas un tel blasphème ;',\n",
       " 'sais que je te sacrifie bien',\n",
       " 'à la vie. Quel bonheur',\n",
       " 'doute pas cher ami, s',\n",
       " 'il y a une lettre anonyme',\n",
       " \"pendant six ans, m '\",\n",
       " 'vous? Oui les jours où',\n",
       " 'aurez pas reçu de M .',\n",
       " 'instant te faire un pont d',\n",
       " 'trouver quelque prétexte honnête, et',\n",
       " \"lettre anonyme; ce n '\",\n",
       " 'et sur mon compte encore .',\n",
       " 'avec tout le monde, même',\n",
       " 'ce que mon mari ne souffrira',\n",
       " 'que mon mari ne se conforme',\n",
       " 'du petit paysan. Si vous',\n",
       " '( y as- tu reconnu',\n",
       " \"? Quoi qu' il puisse\",\n",
       " \"sûr d' une chose :\",\n",
       " 'Ce sont deux mots vains que',\n",
       " 'ne pas être blâmée de toi',\n",
       " 'que mon âme te semble atroce',\n",
       " 'ai déjà que trop trompé en',\n",
       " 'et leur mère; elle prit',\n",
       " 'femme que le remords rendait si',\n",
       " 'folle? pensa- t -',\n",
       " 'homme? Ici pareille incertitude ;',\n",
       " 'plus extrême plaisir! Par bonheur',\n",
       " 'fenêtres garnies de beaux volets verts',\n",
       " \"on avait laissé l' humble\",\n",
       " \"je n' aie pas un\",\n",
       " \", car ma raison s '\",\n",
       " '! Falcoz! Ah! Ducros',\n",
       " \"le ton d' égalité sur\",\n",
       " 'imprimeurs de province et mettez l',\n",
       " \"par bonheur, il n '\",\n",
       " 'que sa femme était innocente ;',\n",
       " 't- il que tout Verrières',\n",
       " 'de Bernard, on le désigne',\n",
       " \"n' ai point de fille\",\n",
       " 'lui faire perdre sa place de',\n",
       " 'six cents francs. On dit',\n",
       " \"quel abîme! voir l '\",\n",
       " 'jardin. En ce moment il',\n",
       " 'promenade au jardin le calma un',\n",
       " 'de ma femme, elle m',\n",
       " 'Elle est fière, nous nous',\n",
       " ', nous nous brouillerons, et',\n",
       " 'nous nous brouillerons, et tout',\n",
       " 'comme un scellé la porte de',\n",
       " \"à s' en servir ,\",\n",
       " 'revenait du village. Elle était',\n",
       " 'fort incertaine aux yeux du froid',\n",
       " \"' occasion de lui parler .\",\n",
       " '. Elle lui remit une lettre',\n",
       " 'avait deviné juste. Au lieu',\n",
       " 'homme encore sans aucune expérience !',\n",
       " 'encore sans aucune expérience! A',\n",
       " \". Je n' ai pas\",\n",
       " 'examiner, et toujours à cause',\n",
       " 'fut sur le point de l',\n",
       " \"de l' accabler des injures\",\n",
       " \"d' elle, et plus\",\n",
       " \"' elle, et plus tranquille\",\n",
       " 'avec Julien. Elle cherchait les',\n",
       " \"il n' en est pas\",\n",
       " 'des gens dans Verrières. -',\n",
       " 'pas. Vous y mettriez de',\n",
       " '-- Ce jeune homme n',\n",
       " \"' est au fond qu '\",\n",
       " \"les ignorais! s' écria\",\n",
       " ', et peut- être il',\n",
       " \"' aurait pas été fâché que\",\n",
       " 'il brouiller deux amis pour une',\n",
       " \"à laquelle il n' a\",\n",
       " 'avec le directeur du dépôt au',\n",
       " 'un des barreaux de fer de',\n",
       " 'Sans doute, se disait -',\n",
       " 'Mme de Rênal, il convient',\n",
       " \"' il ait pour le latin\",\n",
       " \"après tout qu' un paysan\",\n",
       " 'qui se passe chez lui ?',\n",
       " 'personnage de Verrières. - -',\n",
       " 'de Verrières. -- Vous',\n",
       " \"- Vous êtes l' un\",\n",
       " '. Une odalisque du sérail peut',\n",
       " 'leurs thèmes, que vous corrigerez',\n",
       " 'il de la prudence à essayer',\n",
       " 'Que le monde juge sur les',\n",
       " '1830 La parole a été donnée',\n",
       " 'ennemis. M. de Rênal',\n",
       " '. M. de Rênal avait',\n",
       " 'de loger chez lui. Personne',\n",
       " 'la méchanceté des hommes, sur',\n",
       " 'avoir donnés que de les avoir',\n",
       " 'par quartier, et toujours d',\n",
       " \"et toujours d' avance .\",\n",
       " \"reconnaissance pour l' illustre sous\",\n",
       " \"d' obtenir quelque chose de\",\n",
       " 'exercer, et recommença sa réponse',\n",
       " 'air de vouloir se réveiller ,',\n",
       " 'de Rênal, dans laquelle il',\n",
       " \"Mais avant d' arriver chez\",\n",
       " 'le bon curé, le ciel',\n",
       " '; un pauvre garçon comme lui',\n",
       " \", mais la vocation n '\",\n",
       " 'faire des économies, ce qui',\n",
       " 'des économies, ce qui était',\n",
       " 'cents francs payés par quartier qu',\n",
       " 'le même jour. Jamais Julien',\n",
       " 'allé chez cet homme; quelques',\n",
       " 'cabinet de travail de M .',\n",
       " 'toilette et ne pouvait recevoir .',\n",
       " 'une des plus considérables de Verrières',\n",
       " 'attendrissement. Cette disposition fut augmentée',\n",
       " '. Cette disposition fut augmentée par',\n",
       " 'disposé, vint à penser que',\n",
       " 'la conscience de Julien, la',\n",
       " \"Ce n' était pas pour\",\n",
       " 'une demi- phrase latine fut',\n",
       " 'phrase latine, au lieu de',\n",
       " 'latine, au lieu de répondre',\n",
       " \"' un chapitre de la nouvelle\",\n",
       " 'ce M. Valenod, dans',\n",
       " 'le père de M. Valenod',\n",
       " 'Vergy de gros paquets de thèmes',\n",
       " 'il raccommodait assez bien sa réputation',\n",
       " 'petits Valenod. Au milieu du',\n",
       " \"qu' être dupe. -\",\n",
       " 'fait pour arranger les choses ,',\n",
       " 'pour arranger les choses, auprès',\n",
       " 'dans ce siècle à jeter de',\n",
       " \", n' ayant aucune prétention\",\n",
       " \"' ayant aucune prétention personnelle il\",\n",
       " \"libéraux: c' est pour\",\n",
       " 'humeur du maire. Jamais la',\n",
       " \", il s' était conduit\",\n",
       " 'un homme de coeur tandis qu',\n",
       " 'Vergy; mais, dès le',\n",
       " '; mais, dès le surlendemain',\n",
       " \"Une heure ne s' était\",\n",
       " \"heure ne s' était pas\",\n",
       " 'ses conversations avec son mari dès',\n",
       " \"église, dans l' endroit\",\n",
       " 'il à sa femme. Une',\n",
       " \"l' afficheur qui emportait ce\",\n",
       " 'afficheur qui emportait ce gros paquet',\n",
       " 'M. Maslon lui a promis',\n",
       " \"amis qui n' ajoutèrent plus\",\n",
       " '. Leur sang- froid lui',\n",
       " 'vaut à la commune, disait',\n",
       " ', répondait- on, se',\n",
       " 'la congrégation? ses quatre enfants',\n",
       " \"prétexte de remerciement, s '\",\n",
       " 'suis_ il signor_ Geronimo',\n",
       " 'fort gai, qualités qui ,',\n",
       " 'sortais le plus souvent que je',\n",
       " \"sous que coûte l' entrée\",\n",
       " ', et les enfants de rire',\n",
       " 'les enfants de rire. Le',\n",
       " \"- moi Geronimo. Qu '\",\n",
       " \"ne l' auras pas ;\",\n",
       " \"; et d' ailleurs ,\",\n",
       " 'Aussitôt Zingarelli, furieux, se',\n",
       " \"signor_ Geronimo n' alla\",\n",
       " 'à la cour de France .',\n",
       " 'pas lire, écrire, réfléchir',\n",
       " \"dépense d' une telle vie\",\n",
       " \"d' une telle vie est\",\n",
       " \"faire l' associé de Fouqué\",\n",
       " 'si, devenant veuve tout à',\n",
       " 'elle pouvait épouser Julien. Il',\n",
       " \", n' était occupée que\",\n",
       " '. La bonne compagnie de Verrières',\n",
       " 'elle de ne pas trouver de',\n",
       " 'famille que les deux tiers à',\n",
       " 'que les deux tiers à peu',\n",
       " 'Je ne vous demande rien ,',\n",
       " 'ne vous demande rien, lui',\n",
       " \"de Besançon, l' avait\",\n",
       " \", l' avait décidé à\",\n",
       " \"n' a rien. Et\",\n",
       " 'si inutilement pour mon bonheur !',\n",
       " 'inutilement pour mon bonheur! Il',\n",
       " \"' ai pas pris la peine\",\n",
       " 'chose: en apprenant la terrible',\n",
       " \"s' attendait à du désespoir\",\n",
       " 'lui- même il avait trouvé',\n",
       " 'pourrais être veuve, grand Dieu',\n",
       " '! pensa Mme de Rênal .',\n",
       " 'Mais presque au même instant ,',\n",
       " 'au même instant, elle se',\n",
       " 'serai la meurtrière de mon mari',\n",
       " 'M. Valenod, et même',\n",
       " 'après avoir été mis trois ou',\n",
       " 'restât comme précepteur des enfants de',\n",
       " ', était plus au désespoir que',\n",
       " 'le grand matin, M .',\n",
       " 'parla en vain, la nouvelle',\n",
       " 'vain, la nouvelle lettre anonyme',\n",
       " 'donner un soufflet à M .',\n",
       " 'idée de prendre un précepteur chez',\n",
       " ', il pouvait sans honte accepter',\n",
       " 'fer, plia la volonté de',\n",
       " 'de Verrières, et de lui',\n",
       " \"qu' elle serait refusée avec\",\n",
       " 'Julien quitta Verrières. M .',\n",
       " 'certificat de bonne conduite, il',\n",
       " '. Sa vie était passable ,',\n",
       " 'de Rênal, pétrifiée, ne',\n",
       " 'du jour vint rendre le départ',\n",
       " 'vous ne puissiez pas embrasser Stanislas',\n",
       " 'chargés de la défendre! Besançon',\n",
       " \"Julien n' était qu '\",\n",
       " 'hommes distingués. Il avait pris',\n",
       " 'distingués. Il avait pris chez',\n",
       " 'point de se faire arrêter par',\n",
       " 'faire arrêter par les sentinelles il',\n",
       " 'portes, il ne pouvait en',\n",
       " 'la bouche de tous, les',\n",
       " 'considérait le buste du roi ,',\n",
       " 'une petite voix qui cherchait à',\n",
       " 'bleus fort tendres, et vit',\n",
       " \"lui qu' on parlait .\",\n",
       " '- t- il pas inspirer',\n",
       " '; elle lut dans les regards',\n",
       " '- Ah! je comprends ,',\n",
       " 'un garçon: elle avait du',\n",
       " 'immense, faisaient un tapage qui',\n",
       " 'de Dijon; dites que vous',\n",
       " 'y manquerai pas. - -',\n",
       " 'les séminaristes passent ici devant le',\n",
       " 'sens que je vous aime de',\n",
       " \"dit- elle d' un\",\n",
       " '- comtoise prit un air glacial',\n",
       " 'amants paraissait à la porte du',\n",
       " \", l' imagination de celui\",\n",
       " \"l' imagination de celui -\",\n",
       " \"ne songeant qu' à ce\",\n",
       " 'plaça ses deux mains dans les',\n",
       " '. Je lui ai dit que',\n",
       " ', son imagination de dame de',\n",
       " 'vers le billard. Amanda le',\n",
       " \"le plus lentement qu' elle\",\n",
       " 'heure sur le boulevard devant le',\n",
       " 'le boulevard devant le café ;',\n",
       " 'il eût su comment se fâcher',\n",
       " 'quelque auberge, où je reprendrai',\n",
       " 'jamais je parviens à sortir du',\n",
       " 'sortir du séminaire pour quelques heures',\n",
       " 'Amanda. Ce raisonnement était beau',\n",
       " 'drap sans le toucher. Elle',\n",
       " 'sans le toucher. Elle prit',\n",
       " \"m' en vais vous faire\",\n",
       " 'sols au lieu de cinquante que',\n",
       " 'vers le lieu terrible; l',\n",
       " 'porte, lui en indiquait la',\n",
       " 'un lieu solitaire. Au bout',\n",
       " 'immobiles de ses paupières annonçaient l',\n",
       " 'ciel. Julien releva les yeux',\n",
       " 'Julien releva les yeux avec effort',\n",
       " 'ouverte avec difficulté et le portier',\n",
       " 'il était atterré, son coeur',\n",
       " 'mort régnait dans toute la maison',\n",
       " ', le portier à figure sinistre',\n",
       " \"de Julien étaient telles qu '\",\n",
       " 'un pas mal assuré, et',\n",
       " '.- - Plus près ,',\n",
       " 'nouveau sur lui un oeil terrible',\n",
       " \"' approchaient. On le releva\",\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_noir_df = pd.read_csv('../data/book_dfs/rouge_noir_df.csv')\n",
    "\n",
    "for i, row in rouge_noir_df.drop_duplicates('total_word_index').iterrows():\n",
    "    print(get_name_window(row.total_word_index, '798-8'))\n",
    "    if i > 9:\n",
    "        break\n",
    "        \n",
    "get_all_name_windows(rouge_noir_df.drop_duplicates('total_word_index')['total_word_index'].to_list(), \n",
    "                    '798-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d05342-a87d-4572-a066-13ecfe251b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ent_index</th>\n",
       "      <th>Ent_near_entities</th>\n",
       "      <th>Verb_index</th>\n",
       "      <th>Verb_near_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mme</td>\n",
       "      <td>139.0</td>\n",
       "      <td>les</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rênal</td>\n",
       "      <td>129.0</td>\n",
       "      <td>pour</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mole</td>\n",
       "      <td>65.0</td>\n",
       "      <td>ses</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>julien</td>\n",
       "      <td>63.0</td>\n",
       "      <td>le</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mathilde</td>\n",
       "      <td>54.0</td>\n",
       "      <td>dans</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ent_index  Ent_near_entities Verb_index  Verb_near_verbs\n",
       "0       mme              139.0        les            162.0\n",
       "1     rênal              129.0       pour             80.0\n",
       "2      mole               65.0        ses             68.0\n",
       "3    julien               63.0         le             68.0\n",
       "4  mathilde               54.0       dans             55.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr = get_nearest_relations('798-8')\n",
    "\n",
    "character = 'julien'\n",
    "list_len = 5\n",
    "\n",
    "(pd.concat([pd.DataFrame(nr[character])[['near_entities']].dropna().sort_values(by='near_entities', ascending=False)\n",
    " .reset_index().add_prefix('Ent_'), pd.DataFrame(nr[character])[['near_verbs']].dropna()\n",
    " .sort_values(by='near_verbs', ascending=False).reset_index().add_prefix('Verb_')], axis=1\n",
    ")[:list_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c084c09e-98a2-47a0-a153-34779ef9f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_emb_model = get_embeddings_model('798-8')\n",
    "rouge_ent_embeddings = get_entities_embeddings('798-8', rouge_emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806c9b64-ec40-4556-a873-aaf20aadedf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21935812,  0.46988618, -0.13313417,  0.21285127, -0.01042413,\n",
       "        0.14384367,  0.8618946 ,  0.43801   , -0.01129042, -0.5382415 ,\n",
       "       -0.45118925, -0.13251317, -0.68415207,  0.26656255, -0.41121063,\n",
       "       -0.5571151 , -0.38744333, -0.22552618, -0.2715456 , -0.09765779,\n",
       "       -0.3976055 , -0.06343193, -0.8352583 , -0.15384007, -0.29087663,\n",
       "        0.07601301, -0.29443428, -0.05681138, -0.5828162 ,  0.21477747,\n",
       "       -0.70946634,  0.14572687,  0.07114863, -0.08396879, -0.28781366,\n",
       "        0.24529648, -0.1276956 ,  0.0104102 , -0.26252443,  0.05686149,\n",
       "        0.7932738 , -0.8123997 ,  0.25154415, -0.3905342 , -0.768202  ,\n",
       "       -0.30401334,  0.88381624, -0.22547473,  0.03883391,  0.00755687,\n",
       "       -0.25466225, -0.3371966 , -0.2495189 , -0.05299431,  0.12452551,\n",
       "       -0.0933181 , -0.66306806,  0.25034323,  0.40324533,  0.40569687,\n",
       "       -0.04518152, -0.18821898,  0.45650902,  0.25099102,  0.4002452 ,\n",
       "        0.27162552,  0.06135617,  0.34476086,  0.16690722,  0.21773519,\n",
       "       -0.48854044,  0.16335347, -0.01408531, -0.89300936,  0.11021299,\n",
       "       -0.51280403, -0.6267494 , -0.6007578 ,  0.47083196,  0.36326844,\n",
       "       -0.5085766 , -0.6477912 ,  0.05073478,  0.13271767, -0.78877795,\n",
       "       -0.32195282, -0.18782565,  0.21087563, -0.20267929, -0.19898792,\n",
       "       -0.745362  ,  0.05044551,  0.28622398, -0.13095328,  0.25080165,\n",
       "        0.8930387 ,  0.1831063 ,  0.22993545, -0.90509236,  0.31536075],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_ent_embeddings['julien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c1b30-7f3e-44fe-a7dc-701df491d5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
