{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67525bb4-7491-4028-a288-6f8fb3fbf6ee",
   "metadata": {},
   "source": [
    "# Evaluate NER performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40165e0d-85e9-43e7-9450-8bd308ad1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete everything about occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d421b-012d-454c-ae1e-7da6cc13e4a7",
   "metadata": {},
   "source": [
    "## TODO :\n",
    "\n",
    "- faire le groundtruth dataset\n",
    "- faire textually close dataset\n",
    "- faire le lax close dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ff5f78-7dc8-405d-9bc0-249b9970993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# from character_extraction import *\n",
    "from embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e0b368-12ea-489b-92c9-acae728158ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_data_df = pd.DataFrame([ \n",
    "('agde', 'Monsieur Agde',13,'M',36930), \n",
    "('altamira','Comte Altamira',26,'M',97835),\n",
    "('amanda', 'Mme Amanda Binet',17,'F',60381),\n",
    "('appert', 'M Appert',8,'M',2363),\n",
    "('castanède','Abbé Castanède',19,'M',64861),\n",
    "('caylus','Comte Caylus',24,'M',94378),\n",
    "('chélan','Abbé Chélan',6,'M',1929),\n",
    "('croisenois','Monsieur Croisenois',23,'M',94374),\n",
    "('danton','Monsieur Danton',1,'M', 15),\n",
    "('derville','Madame Derville',12,'F',13130),\n",
    "('falcoz','Monsieur Falcoz',14,'M',45151),\n",
    "('fervaques','Madame Fervaques',25,'F',96924),\n",
    "('fouqué','Monsieur Fouqué',10,'M',7451),\n",
    "('frilair','Monsieur Frilair',15,'M',53833),\n",
    "('geronimo','Monsieur Geronimo',16,'M',55797),\n",
    "('korasoff','Monsieur Korasoff',27,'M',102772),\n",
    "('julien','Monsieur Julien Sorel',3,'M',4751),\n",
    "('louise','Madame Louise Rênal',7,'F',45391),\n",
    "('maslon','Monsieur Maslon',5,'M',1900),\n",
    "('mathilde','Mademoiselle Mathilde Sorel',21,'F',90709),\n",
    "('norbert','Monsieur Norbert Mole',20,'M',87123),\n",
    "('pirard','Monsieur Pirard',18,'M',62166),\n",
    "('rênal','Monsieur de Rênal',2,'M', 605),\n",
    "('rênal','Madame Louise Rênal',7,'F', 2214),\n",
    "('sorel','Monsieur Julien Sorel',3,'M', 940),\n",
    "('tanbeau','Monsieur Tanbeau',22,'M',92323),\n",
    "('valenod','Monsieur Valenod',4,'M',1724),\n",
    "('élisa','Mademoiselle Élisa',11,'F',12267),\n",
    "('mole', 'Mademoiselle Mathilde Sorel', 21,'F',90768),\n",
    "('mole', 'Monsieur de la Mole',9,'M',2610)],\n",
    "columns=['name', 'entity','entity_ID', 'gender','first_appearance' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967ed151-f492-4a91-8da5-547462321b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustering_metrics(embeddings, embeddings_type):\n",
    "    '''Given embeddings, and their ground truth data type, computes several clustering performance\n",
    "    metrics. The right `ground_truth_data_df`, `textually_close_ent_ground_truth_df` or \n",
    "    `lax_ent_ground_truth_df` should have been loaded into memory before calling this function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dictionary\n",
    "        The dictionary containing each entity and their associated embedding vector\n",
    "    embeddings_type : str\n",
    "        The matching ground truth data type for the given embeddings (either 'first_version',\n",
    "        'textually_close' or 'lax')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    same_entityness : list\n",
    "        A list containing the performance metrics with regards to the 'same_entityness' axis\n",
    "    gender : list\n",
    "        A list containing the performance metrics with regards to the 'gender' axis\n",
    "    first_appearance : list\n",
    "        A list containing the performance metrics with regards to the 'first_appearance' axis\n",
    "    '''\n",
    "    \n",
    "    # SAME ENTITY-NESS\n",
    "    same_entityness = []\n",
    "    \n",
    "    mask_embs_entity = [(k, \n",
    "                         embeddings[k], \n",
    "                         ground_truth_data_df[ground_truth_data_df['name'] == k]['entity_ID'].values[0]) \n",
    "                        for k in embeddings \n",
    "                        if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "        \n",
    "    tmp_df = pd.DataFrame(mask_embs_entity)\n",
    "    same_entityness.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                                            np.array(tmp_df[2]), \n",
    "                                                            metric='euclidean', \n",
    "                                                            random_state=0))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), \n",
    "                                                                   np.array(tmp_df[2])))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), \n",
    "                                                                np.array(tmp_df[2])))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_entity)\n",
    "    entityness_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    k_choice = 45 # obtained by the elbow method\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(entityness_matrix, )\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.adjusted_rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.mutual_info_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.adjusted_mutual_info_score(np.array(tmp_df[2]), \n",
    "                                                                      predicted_clusters, \n",
    "                                                                      average_method='arithmetic'))\n",
    "    \n",
    "    \n",
    "    # GENDER\n",
    "    gender = []\n",
    "    \n",
    "    mask_embs_gender = [(k, \n",
    "                         embeddings[k], \n",
    "                         ground_truth_data_df[ground_truth_data_df['name'] == k]['gender'].values[0]) \n",
    "                        for k in embeddings \n",
    "                        if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "\n",
    "    tmp_df = pd.DataFrame(mask_embs_gender)\n",
    "    gender.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                                   np.array(tmp_df[2] == 'M').astype(int), \n",
    "                                                   metric='euclidean', \n",
    "                                                   random_state=0))\n",
    "    gender.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), np.array(tmp_df[2])))\n",
    "    gender.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), np.array(tmp_df[2])))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_gender)\n",
    "    gender_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    k_choice = 2 # two genders in PG literature (men and women)\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(gender_matrix)\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    gender.append(sklearn.metrics.rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.adjusted_rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.mutual_info_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.adjusted_mutual_info_score(np.array(tmp_df[2]), predicted_clusters, \n",
    "                                                             average_method='arithmetic'))\n",
    "    \n",
    "    # FIRST APPEARANCE\n",
    "    first_appearance = []\n",
    "    \n",
    "    # build distance matrix \n",
    "    mask_embs_appear = [(k, \n",
    "                         embeddings[k], \n",
    "                         ground_truth_data_df[ground_truth_data_df['name'] == k]['first appearance'].values[0]) \n",
    "                        for k in embeddings \n",
    "                        if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "        \n",
    "    tmp_df = pd.DataFrame(mask_embs_appear)\n",
    "    appear_matrix = np.array(tmp_df[2]).reshape(-1, 1)\n",
    "\n",
    "    # k based both on \"vector\" being predict (first appearance in book) and overall clustering\n",
    "    # using elbow shape\n",
    "    k_choice = 17\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(appear_matrix)\n",
    "\n",
    "    first_appearance.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                         kmean.predict(np.array(tmp_df[2]).reshape(-1,1)), \n",
    "                                         metric='euclidean', \n",
    "                                         random_state=0))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), \n",
    "                                 kmean.predict(np.array(tmp_df[2]).reshape(-1,1))))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), \n",
    "                                 kmean.predict(np.array(tmp_df[2]).reshape(-1,1))))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_appear)\n",
    "    ground_truth_based_clusters = kmean.predict(np.array(tmp_df[2]).reshape(-1,1))\n",
    "    appear_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(appear_matrix)\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.rand_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.adjusted_rand_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.mutual_info_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.adjusted_mutual_info_score(ground_truth_based_clusters, predicted_clusters, \n",
    "                                                                       average_method='arithmetic'))\n",
    "    \n",
    "    return same_entityness, gender, first_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86dbd94-1ab5-4bbe-91b4-41dcb7f8009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clustering_metrics(embeddings, embeddings_type):\n",
    "    '''Given embeddings, and their ground truth data type, display in a table several\n",
    "    clustering performance metrics. The right `ground_truth_data_df`, \n",
    "    `textually_close_ent_ground_truth_df` or `lax_ent_ground_truth_df` should have been \n",
    "    loaded into memory before calling this function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dictionary\n",
    "        The dictionary containing each entity and their associated embedding vector\n",
    "    embeddings_type : str\n",
    "        The matching ground truth data type for the given embeddings (either 'first_version',\n",
    "        'textually_close' or 'lax')\n",
    "    '''\n",
    "    \n",
    "    same_entityness, gender, first_appearance = get_clustering_metrics(embeddings, embeddings_type)\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print('|                            | Same Entity-ness |  Gender  | First Appearance |')\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print(f'| Silhouette Score           |     {same_entityness[0]:8.5f}     | {gender[0]:8.5f} |  {first_appearance[0]:8.5f}     |')\n",
    "    print(f'| Calinski Harabasz Score    |     {same_entityness[1]:8.5f}     | {gender[1]:8.5f} |  {first_appearance[1]:8.5f}     |')\n",
    "    print(f'| Davies Bouldin Score       |     {same_entityness[2]:8.5f}     | {gender[2]:8.5f} |  {first_appearance[2]:8.5f}     |')\n",
    "    print(f'| Rand Score                 |     {same_entityness[3]:8.5f}     | {gender[3]:8.5f} |  {first_appearance[3]:8.5f}     |')\n",
    "    print(f'| Adjusted Rand Score        |     {same_entityness[4]:8.5f}     | {gender[4]:8.5f} |  {first_appearance[4]:8.5f}     |')\n",
    "    print(f'| Mutual Info Score          |     {same_entityness[5]:8.5f}     | {gender[5]:8.5f} |  {first_appearance[5]:8.5f}     |')\n",
    "    print(f'| Adjusted Mutual Info Score |     {same_entityness[6]:8.5f}     | {gender[6]:8.5f} |  {first_appearance[6]:8.5f}     |')\n",
    "    print('--------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4e9982-3568-4f2b-a461-568d6f935ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_base_cased were not used when initializing FlaubertModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing FlaubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████████████████████| 146/146 [13:26<00:00,  5.53s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = french_word_embeddings('flaubert/flaubert_base_cased', '798-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f2f09-ceee-4adc-9a68-f428b6004327",
   "metadata": {},
   "source": [
    "# ATTENTION check how it writes a torch tensor and how it is reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e7064e-0bc7-42d4-a482-720a2830e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('word_embeddings.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['key','value'])\n",
    "    for k,v in embeddings_dict.items() :\n",
    "        w.writerow([k,v.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ebe0f3-30f0-4ad0-8772-e343e6deb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open('word_embeddings.csv', newline='') as pscfile:\n",
    "    reader = csv.DictReader(pscfile)\n",
    "    for row in reader:\n",
    "        embeddings_dict[row['key']] = torch.from_numpy(numpy.array(row['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5056dd2-573b-407f-868c-d12f3507a231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = get_entities_embeddings('798-8', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695eac98-52f1-4807-9e0d-f6e30c60468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_type = 'first_version'\n",
    "\n",
    "print('Word2Vec Embeddings - Skip-gram')\n",
    "print_clustering_metrics(embeddings, embeddings_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35df9b1-0480-4524-b6db-de1a8d26e725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
