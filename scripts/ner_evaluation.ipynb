{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67525bb4-7491-4028-a288-6f8fb3fbf6ee",
   "metadata": {},
   "source": [
    "# Evaluate NER performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40165e0d-85e9-43e7-9450-8bd308ad1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete everything about occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c455b6-0240-4773-8973-0a9742bd2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_embeddings(gutenberg_id, emb_model, grouped_entities=False):\n",
    "    '''Given the book DF and the embeddings model, returns a dictionary for the embeddings\n",
    "    corresponding to each entity (entity list obtained from the book's DF).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gutenberg_id : int\n",
    "        The book's Project Gutenberg ID\n",
    "    emb_model : Model\n",
    "        The trained (gensim) embeddings model\n",
    "    grouped_entities : bool, optional\n",
    "        Flag indicating whether the NER pipeline used to create the entities was configured to output \n",
    "        grouped_entities or not (default is False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ent_vectors : dictionary\n",
    "        A dictionary containing each entity and their associated embedding vector\n",
    "    '''\n",
    "    \n",
    "    book_df = get_book_df(gutenberg_id, grouped_entities).drop_duplicates('total_word_index')\n",
    "    ent_vectors = {}\n",
    "    for n in book_df['full_word'].unique():\n",
    "        if n in emb_model.wv.index_to_key:\n",
    "            ent_vectors[n] = emb_model.wv[n]\n",
    "            \n",
    "    return ent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967ed151-f492-4a91-8da5-547462321b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustering_metrics(embeddings, embeddings_type):\n",
    "    '''Given embeddings, and their ground truth data type, computes several clustering performance\n",
    "    metrics. The right `ground_truth_data_df`, `textually_close_ent_ground_truth_df` or \n",
    "    `lax_ent_ground_truth_df` should have been loaded into memory before calling this function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dictionary\n",
    "        The dictionary containing each entity and their associated embedding vector\n",
    "    embeddings_type : str\n",
    "        The matching ground truth data type for the given embeddings (either 'first_version',\n",
    "        'textually_close' or 'lax')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    same_entityness : list\n",
    "        A list containing the performance metrics with regards to the 'same_entityness' axis\n",
    "    gender : list\n",
    "        A list containing the performance metrics with regards to the 'gender' axis\n",
    "    first_appearance : list\n",
    "        A list containing the performance metrics with regards to the 'first_appearance' axis\n",
    "    '''\n",
    "    \n",
    "    # SAME ENTITY-NESS\n",
    "    same_entityness = []\n",
    "    \n",
    "    if embeddings_type == 'first_version':\n",
    "        mask_embs_entity = [(k, \n",
    "                             embeddings[k], \n",
    "                             ground_truth_data_df[ground_truth_data_df['name'] == k]['entity_ID'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "    elif embeddings_type == 'textually_close':\n",
    "        mask_embs_entity = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             textually_close_ent_ground_truth_df[textually_close_ent_ground_truth_df['name'] == k]['entity_ID'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in textually_close_ent_ground_truth_df['name'].tolist()]\n",
    "    elif embeddings_type == 'lax':\n",
    "        mask_embs_entity = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             lax_ent_ground_truth_df[lax_ent_ground_truth_df['name'] == k]['entity_ID'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in lax_ent_ground_truth_df['name'].tolist()]\n",
    "        \n",
    "    tmp_df = pd.DataFrame(mask_embs_entity)\n",
    "    same_entityness.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                                            np.array(tmp_df[2]), \n",
    "                                                            metric='euclidean', \n",
    "                                                            random_state=0))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), \n",
    "                                                                   np.array(tmp_df[2])))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), \n",
    "                                                                np.array(tmp_df[2])))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_entity)\n",
    "    entityness_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    k_choice = 45 # obtained by the elbow method\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(entityness_matrix, )\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    same_entityness.append(sklearn.metrics.rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.adjusted_rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.mutual_info_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    same_entityness.append(sklearn.metrics.adjusted_mutual_info_score(np.array(tmp_df[2]), \n",
    "                                                                      predicted_clusters, \n",
    "                                                                      average_method='arithmetic'))\n",
    "    \n",
    "    \n",
    "    # GENDER\n",
    "    gender = []\n",
    "    \n",
    "    if embeddings_type == 'first_version':\n",
    "        mask_embs_gender = [(k, \n",
    "                             embeddings[k], \n",
    "                             ground_truth_data_df[ground_truth_data_df['name'] == k]['gender'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "    elif embeddings_type == 'textually_close':\n",
    "        mask_embs_gender = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             textually_close_ent_ground_truth_df[textually_close_ent_ground_truth_df['name'] == k]['gender'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in textually_close_ent_ground_truth_df['name'].tolist()]\n",
    "    elif embeddings_type == 'lax':\n",
    "        mask_embs_gender = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             lax_ent_ground_truth_df[lax_ent_ground_truth_df['name'] == k]['gender'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in lax_ent_ground_truth_df['name'].tolist()]\n",
    "\n",
    "    tmp_df = pd.DataFrame(mask_embs_gender)\n",
    "    gender.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                                   np.array(tmp_df[2] == 'M').astype(int), \n",
    "                                                   metric='euclidean', \n",
    "                                                   random_state=0))\n",
    "    gender.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), np.array(tmp_df[2])))\n",
    "    gender.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), np.array(tmp_df[2])))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_gender)\n",
    "    gender_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    k_choice = 2 # two genders in PG literature (men and women)\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(gender_matrix)\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    gender.append(sklearn.metrics.rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.adjusted_rand_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.mutual_info_score(np.array(tmp_df[2]), predicted_clusters))\n",
    "    gender.append(sklearn.metrics.adjusted_mutual_info_score(np.array(tmp_df[2]), predicted_clusters, \n",
    "                                                             average_method='arithmetic'))\n",
    "    \n",
    "    # FIRST APPEARANCE\n",
    "    first_appearance = []\n",
    "    \n",
    "    # build distance matrix \n",
    "    if embeddings_type == 'first_version':\n",
    "        mask_embs_appear = [(k, \n",
    "                             embeddings[k], \n",
    "                             ground_truth_data_df[ground_truth_data_df['name'] == k]['first appearance'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k.lower() in ground_truth_data_df['name'].tolist()]\n",
    "    elif embeddings_type == 'textually_close':\n",
    "        mask_embs_appear = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             textually_close_ent_ground_truth_df[textually_close_ent_ground_truth_df['name'] == k]['first appearance'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in textually_close_ent_ground_truth_df['name'].tolist()]\n",
    "    elif embeddings_type == 'lax':\n",
    "        mask_embs_appear = [(k, \n",
    "                             embeddings[k]['MASK'], \n",
    "                             lax_ent_ground_truth_df[lax_ent_ground_truth_df['name'] == k]['first appearance'].values[0]) \n",
    "                            for k in embeddings \n",
    "                            if k in lax_ent_ground_truth_df['name'].tolist()]\n",
    "        \n",
    "    tmp_df = pd.DataFrame(mask_embs_appear)\n",
    "    appear_matrix = np.array(tmp_df[2]).reshape(-1, 1)\n",
    "\n",
    "    # k based both on \"vector\" being predict (first appearance in book) and overall clustering\n",
    "    # using elbow shape\n",
    "    k_choice = 17\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(appear_matrix)\n",
    "\n",
    "    first_appearance.append(sklearn.metrics.silhouette_score(np.array(tmp_df[1].tolist()), \n",
    "                                         kmean.predict(np.array(tmp_df[2]).reshape(-1,1)), \n",
    "                                         metric='euclidean', \n",
    "                                         random_state=0))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.calinski_harabasz_score(np.array(tmp_df[1].tolist()), \n",
    "                                 kmean.predict(np.array(tmp_df[2]).reshape(-1,1))))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.davies_bouldin_score(np.array(tmp_df[1].tolist()), \n",
    "                                 kmean.predict(np.array(tmp_df[2]).reshape(-1,1))))\n",
    "    \n",
    "    tmp_df = pd.DataFrame(mask_embs_appear)\n",
    "    ground_truth_based_clusters = kmean.predict(np.array(tmp_df[2]).reshape(-1,1))\n",
    "    appear_matrix = np.array([np.array(emb) for emb in tmp_df[1]])\n",
    "    kmean = KMeans(n_clusters=k_choice, random_state=0).fit(appear_matrix)\n",
    "    predicted_clusters = kmean.predict(np.array([np.array(emb) for emb in tmp_df[1]]))\n",
    "    \n",
    "    first_appearance.append(sklearn.metrics.rand_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.adjusted_rand_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.mutual_info_score(ground_truth_based_clusters, predicted_clusters))\n",
    "    first_appearance.append(sklearn.metrics.adjusted_mutual_info_score(ground_truth_based_clusters, predicted_clusters, \n",
    "                                                                       average_method='arithmetic'))\n",
    "    \n",
    "    return same_entityness, gender, first_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86dbd94-1ab5-4bbe-91b4-41dcb7f8009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clustering_metrics(embeddings, embeddings_type):\n",
    "    '''Given embeddings, and their ground truth data type, display in a table several\n",
    "    clustering performance metrics. The right `ground_truth_data_df`, \n",
    "    `textually_close_ent_ground_truth_df` or `lax_ent_ground_truth_df` should have been \n",
    "    loaded into memory before calling this function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : dictionary\n",
    "        The dictionary containing each entity and their associated embedding vector\n",
    "    embeddings_type : str\n",
    "        The matching ground truth data type for the given embeddings (either 'first_version',\n",
    "        'textually_close' or 'lax')\n",
    "    '''\n",
    "    \n",
    "    same_entityness, gender, first_appearance = get_clustering_metrics(embeddings, embeddings_type)\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print('|                            | Same Entity-ness |  Gender  | Occupation | First Appearance |')\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print(f'| Silhouette Score           |     {same_entityness[0]:8.5f}     | {gender[0]:8.5f} |  {first_appearance[0]:8.5f}     |')\n",
    "    print(f'| Calinski Harabasz Score    |     {same_entityness[1]:8.5f}     | {gender[1]:8.5f} |  {first_appearance[1]:8.5f}     |')\n",
    "    print(f'| Davies Bouldin Score       |     {same_entityness[2]:8.5f}     | {gender[2]:8.5f} |  {first_appearance[2]:8.5f}     |')\n",
    "    print(f'| Rand Score                 |     {same_entityness[3]:8.5f}     | {gender[3]:8.5f} |  {first_appearance[3]:8.5f}     |')\n",
    "    print(f'| Adjusted Rand Score        |     {same_entityness[4]:8.5f}     | {gender[4]:8.5f} |  {first_appearance[4]:8.5f}     |')\n",
    "    print(f'| Mutual Info Score          |     {same_entityness[5]:8.5f}     | {gender[5]:8.5f} |  {first_appearance[5]:8.5f}     |')\n",
    "    print(f'| Adjusted Mutual Info Score |     {same_entityness[6]:8.5f}     | {gender[6]:8.5f} |  {first_appearance[6]:8.5f}     |')\n",
    "    print('--------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84e790-680b-41aa-af44-f7ad6041a725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-stendhal]",
   "language": "python",
   "name": "conda-env-.conda-stendhal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
